{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining and Machine Learning\n",
    "### Clasification using Neural Networks and Deep Learning\n",
    "#### Edgar Acuna \n",
    "#### April 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1. Neural Nets applied to the prediction of the final grade based on the first two exams: E1 and E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv(\"http://academic.uprm.edu/eacuna/eje1dis.csv\")\n",
    "df=pd.read_csv(\"c://PW-PR/eje1dis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convirtiendo en matriz la tabla de predictoras y la columna de clases\n",
    "y=df['Nota']\n",
    "X=df.iloc[:,0:2]\n",
    "#creando una columna \"pass\" numerica para representar las clases\n",
    "lb_make = LabelEncoder()\n",
    "df[\"pass\"] = lb_make.fit_transform(df[\"Nota\"])\n",
    "y2=df['pass']\n",
    "y1=y2.as_matrix()\n",
    "X1=X.as_matrix()\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X1)\n",
    "#StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "#X1= scaler.transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=5, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=99, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a neural net with one hidden layer containing 5 units\n",
    "mlp = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(5),max_iter=1000,random_state=99)\n",
    "mlp.fit(X1, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.93306393e+01, -2.19847626e-02,  4.67280387e+01,\n",
       "         -1.21251200e+01, -1.67606515e+01],\n",
       "        [ 9.31589043e+01, -3.73206703e-01,  4.15846672e+01,\n",
       "         -1.23368759e+01, -3.21037745e+00]]), array([[-7.01419931e-04],\n",
       "        [ 9.44058482e-01],\n",
       "        [ 1.10475826e-02],\n",
       "        [ 1.96857243e+00],\n",
       "        [-1.35496680e+00]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing  the weights\n",
    "mlp.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-7.44811572,  0.45692388,  1.39966161, -0.16317004,  0.57152039]),\n",
       " array([-51.31888278])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing the biases\n",
    "mlp.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.00000000e+00],\n",
       "       [2.22044605e-16, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [2.22044605e-16, 1.00000000e+00],\n",
       "       [3.10862447e-15, 1.00000000e+00],\n",
       "       [6.56805055e-10, 9.99999999e-01],\n",
       "       [1.19992905e-12, 1.00000000e+00],\n",
       "       [4.33475522e-09, 9.99999996e-01],\n",
       "       [2.44449664e-08, 9.99999976e-01],\n",
       "       [1.19239471e-07, 9.99999881e-01],\n",
       "       [6.26212371e-09, 9.99999994e-01],\n",
       "       [8.37275879e-04, 9.99162724e-01],\n",
       "       [1.70068306e-03, 9.98299317e-01],\n",
       "       [2.60741650e-10, 1.00000000e+00],\n",
       "       [1.20121468e-10, 1.00000000e+00],\n",
       "       [3.12620131e-01, 6.87379869e-01],\n",
       "       [8.63373567e-06, 9.99991366e-01],\n",
       "       [3.77435916e-06, 9.99996226e-01],\n",
       "       [2.69701921e-02, 9.73029808e-01],\n",
       "       [1.20471486e-04, 9.99879529e-01],\n",
       "       [1.78931027e-01, 8.21068973e-01],\n",
       "       [2.26344461e-02, 9.77365554e-01],\n",
       "       [1.69525938e-04, 9.99830474e-01],\n",
       "       [5.47287861e-07, 9.99999453e-01],\n",
       "       [9.93102033e-01, 6.89796709e-03],\n",
       "       [9.99999822e-01, 1.78404967e-07],\n",
       "       [6.06737711e-01, 3.93262289e-01],\n",
       "       [8.91513196e-01, 1.08486804e-01],\n",
       "       [9.70015752e-01, 2.99842477e-02],\n",
       "       [9.99980681e-01, 1.93191898e-05],\n",
       "       [9.68049932e-01, 3.19500677e-02],\n",
       "       [9.99963864e-01, 3.61356025e-05]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the posterior probabilities\n",
    "mlp.predict_proba(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  0]\n",
      " [ 0 24]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating the prediction matrix\n",
    "pred=mlp.predict(X1)\n",
    "print(confusion_matrix(y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este es el numero de errores= 0\n"
     ]
    }
   ],
   "source": [
    "#Calculating the number of errors\n",
    "error=(y!=pred).sum()\n",
    "print( \"Este es el numero de errores=\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f       1.00      1.00      1.00         8\n",
      "           p       1.00      1.00      1.00        24\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        32\n",
      "   macro avg       1.00      1.00      1.00        32\n",
      "weighted avg       1.00      1.00      1.00        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizando la fromtera de decision\n",
    "from matplotlib.colors import ListedColormap\n",
    "mlp = MLPClassifier(solver=\"lbfgs\",hidden_layer_sizes=(5),max_iter=1000,random_state=99)\n",
    "mlp.fit(X1, y1) \n",
    "eje1=np.arange(start = X1[:, 0].min()-1, stop = X1[:, 0].max() + 1, step = 0.1)\n",
    "eje2=np.arange(start = X1[:, 1].min()-1, stop = X1[:, 1].max() + 1, step = 0.11)\n",
    "Y1, Y2 = np.meshgrid(eje1,eje2)\n",
    "pred2=mlp.predict(np.c_[Y1.ravel(), Y2.ravel()]).reshape(Y1.shape)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pcolormesh(Y1, Y2, pred2,cmap=plt.cm.Paired)\n",
    "# Plot also the training points#\n",
    "plt.scatter(X1[:, 0], X1[:, 1], c=y2, edgecolors='k')\n",
    "plt.xlabel('Ex1')\n",
    "plt.ylabel('Ex2')\n",
    "plt.xlim(Y1.min(), Y1.max())\n",
    "plt.ylim(Y2.min(), Y2.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 5), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=99, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a neural net with two hidden layers containing 5 units each of them\n",
    "mlp2 = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(5,5),max_iter=1000,random_state=99)\n",
    "mlp2.fit(X1, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.23049524, -0.02207448,  0.63049713, -0.64444712,  0.36133947],\n",
       "        [-0.39755451, -0.37472974, -0.81520733,  1.16250735, -0.9975528 ]]),\n",
       " array([[-0.16196165,  0.52198852,  0.36004258, -0.62957092,  0.28294691],\n",
       "        [-0.44665223,  0.084192  , -0.32181481,  0.48976489,  0.50820058],\n",
       "        [-0.43132982,  0.14973231, -0.62677501, -0.13685051, -0.6418174 ],\n",
       "        [-0.55149494, -0.49373762,  0.0625446 , -0.65435683, -0.45661181],\n",
       "        [-0.76444363,  0.58263972,  0.0809211 , -0.51503376,  0.65182766]]),\n",
       " array([[ 0.66983668],\n",
       "        [-0.0825381 ],\n",
       "        [ 0.94532955],\n",
       "        [-0.06752363],\n",
       "        [-0.30298109]])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing  the weights\n",
    "mlp2.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.49242105,  0.45692388, -0.22506937, -0.00865967,  0.7918344 ]),\n",
       " array([ 0.06520198, -0.71764652,  0.03837523,  0.21710789,  0.4598108 ]),\n",
       " array([0.11201181])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing  the biases\n",
    "mlp2.intercepts_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has 51 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  5]\n",
      " [ 2 22]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating the prediction matrix\n",
    "pred=mlp2.predict(X1)\n",
    "print(confusion_matrix(y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7 errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2. Nnets applied to Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      2\n",
       "1     1    85    66    29     0  26.6  0.351   31      1\n",
       "2     8   183    64     0     0  23.3  0.672   32      2\n",
       "3     1    89    66    23    94  28.1  0.167   21      1\n",
       "4     0   137    40    35   168  43.1  2.288   33      2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#url= \"http://academic.uprm.edu/eacuna/diabetes.dat\"\n",
    "url=\"c://PW-PR/diabetes.dat\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = pd.read_table(url, names=names)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['class']\n",
    "X=data.iloc[:,0:8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "y1=y.as_matrix()\n",
    "X1=X.as_matrix()\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X_train)\n",
    "#StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "#X_train= scaler.transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=20, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training a NN with one hidden layer and 20 units\n",
    "mlp=MLPClassifier(hidden_layer_sizes=(20),max_iter=500)\n",
    "mlp.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7447916666666666"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.88      0.82       124\n",
      "           2       0.69      0.50      0.58        68\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       192\n",
      "   macro avg       0.73      0.69      0.70       192\n",
      "weighted avg       0.74      0.74      0.73       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The overfitting problem in Neural Nets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7708333333333334"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 20 units\n",
    "mlp1=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(5),max_iter=1000)\n",
    "mlp1.fit(X1, y1) \n",
    "mlp1.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7981770833333334"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 20 units\n",
    "mlp2=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(20),max_iter=1000)\n",
    "mlp2.fit(X1, y1) \n",
    "mlp2.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8046875"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 50 units\n",
    "mlp3=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(50),max_iter=1000)\n",
    "mlp3.fit(X1, y1) \n",
    "mlp3.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8671875"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 100 units\n",
    "mlp4=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(100),max_iter=1000)\n",
    "mlp4.fit(X1, y1) \n",
    "mlp4.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9921875"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 200 units\n",
    "mlp5=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(200),max_iter=5000)\n",
    "mlp5.fit(X1, y1) \n",
    "mlp5.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 500 units\n",
    "mlp6=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(500),max_iter=5000)\n",
    "mlp6.fit(X1, y1) \n",
    "mlp6.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8229166666666666"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 20 units, weight decay with penalty .1\n",
    "mlp6=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(20),alpha=.1,max_iter=5000)\n",
    "mlp6.fit(X1, y1) \n",
    "mlp6.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7994791666666666"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 20 units, weight decay with penalty 5\n",
    "mlp6=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(20),alpha=5,max_iter=5000)\n",
    "mlp6.fit(X1, y1) \n",
    "mlp6.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8567708333333334"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training a NN with two hidden layer and 20 units in each of them\n",
    "mlp22=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(20,20),max_iter=5000)\n",
    "mlp22.fit(X1, y1) \n",
    "mlp22.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy estimated by CV is: 0.7240772385509228\n"
     ]
    }
   ],
   "source": [
    "#Estimating the accuracy using cross validation(5-neurons)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(mlp1, X1, y1, cv=10)\n",
    "print ('The accuracy estimated by CV is:', scores.mean())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy estimated by CV is: 0.7460697197539303\n"
     ]
    }
   ],
   "source": [
    "#Estimating the accuracy using cross validation(20 neurons)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(mlp2, X1, y1, cv=10)\n",
    "print ('The accuracy estimated by CV is:', scores.mean())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy estimated by CV is: 0.7357313738892687\n"
     ]
    }
   ],
   "source": [
    "#Estimating the accuracy using cross validation(50 neurons)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(mlp3, X1, y1, cv=10)\n",
    "print ('The accuracy estimated by CV is:', scores.mean())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy estimated by CV is: 0.7200786056049215\n"
     ]
    }
   ],
   "source": [
    "#Estimating the accuracy using cross validation(100 neurons)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(mlp4, X1, y1, cv=10)\n",
    "print ('The accuracy estimated by CV is:', scores.mean())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3. Nnet  applied to Landsat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargando el conjunto de datos Landsat\n",
    "#url='http://academic.uprm.edu/eacuna/landsat.txt'\n",
    "url='c://PW-PR/landsat.data'\n",
    "data = pd.read_table(url, header=None,delim_whitespace=True)\n",
    "y=data.iloc[:,36]\n",
    "X=data.iloc[:,0:36]\n",
    "#y1=y.as_matrix()\n",
    "#X1=X.as_matrix()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "X_train= scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(50, 50, 50), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Holdout estimacion of teh accuracy  with  3 layers and 50 nuronss in each of them\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "mlp=MLPClassifier(hidden_layer_sizes=(50,50,50),max_iter=500)\n",
    "mlp.fit(X_train, y_train) \n",
    "mlp.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[383   1   2   0   4   0]\n",
      " [  0 162   0   0   0   1]\n",
      " [  2   0 306  28   1  23]\n",
      " [  2   3  54  56   2  62]\n",
      " [ 11   1   2   0 149   8]\n",
      " [  0   2  26  16  21 281]]\n"
     ]
    }
   ],
   "source": [
    "pred=mlp.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.98      0.97       390\n",
      "           2       0.96      0.99      0.98       163\n",
      "           3       0.78      0.85      0.82       360\n",
      "           4       0.56      0.31      0.40       179\n",
      "           5       0.84      0.87      0.86       171\n",
      "           7       0.75      0.81      0.78       346\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1609\n",
      "   macro avg       0.81      0.80      0.80      1609\n",
      "weighted avg       0.82      0.83      0.82      1609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Ejemplo de Deep Learning aplicado a Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54323. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>5 hours 22 mins</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/La_Paz</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.1.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>3 months and 4 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_edgar2017_gwzc6t</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.584 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54323</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.5.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  --------------------------------\n",
       "H2O cluster uptime:         5 hours 22 mins\n",
       "H2O cluster timezone:       America/La_Paz\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.1.2\n",
       "H2O cluster version age:    3 months and 4 days\n",
       "H2O cluster name:           H2O_from_python_edgar2017_gwzc6t\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.584 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54323\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.5.5 final\n",
       "--------------------------  --------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init(ip=\"localhost\", port=54323)\n",
    "from h2o.estimators.deeplearning import H2OAutoEncoderEstimator, H2ODeepLearningEstimator\n",
    "#h2o.connect()\n",
    "#h2o.no_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "diabetes = h2o.import_file(\"https://academic.uprm.edu/eacuna/diabetes.dat\")\n",
    "myx=['C1','C2','C3','C4','C5','C6','C7','C8']\n",
    "diabetes['C9']=diabetes['C9'].asfactor()\n",
    "myy=\"C9\"\n",
    "dl_model = H2ODeepLearningEstimator(hidden=[10,10],epochs=200)\n",
    "dl_model.train(myx, myy, training_frame=diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n",
      "[0.8098958333333334]\n"
     ]
    }
   ],
   "source": [
    "y_pred=dl_model.predict(diabetes)\n",
    "print( (y_pred['predict']==diabetes['C9']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.1318145213206079\n",
      "RMSE: 0.3630626961292056\n",
      "LogLoss: 0.4038698894039883\n",
      "Mean Per-Class Error: 0.19762686567164178\n",
      "AUC: 0.883026119402985\n",
      "pr_auc: 0.8029396655062471\n",
      "Gini: 0.7660522388059701\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.44036121752012775: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>414.0</td>\n",
       "<td>86.0</td>\n",
       "<td>0.172</td>\n",
       "<td> (86.0/500.0)</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>60.0</td>\n",
       "<td>208.0</td>\n",
       "<td>0.2239</td>\n",
       "<td> (60.0/268.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>474.0</td>\n",
       "<td>294.0</td>\n",
       "<td>0.1901</td>\n",
       "<td> (146.0/768.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       1    2    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "1      414  86   0.172    (86.0/500.0)\n",
       "2      60   208  0.2239   (60.0/268.0)\n",
       "Total  474  294  0.1901   (146.0/768.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4403612</td>\n",
       "<td>0.7402135</td>\n",
       "<td>187.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2258397</td>\n",
       "<td>0.8272667</td>\n",
       "<td>274.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7407159</td>\n",
       "<td>0.7429245</td>\n",
       "<td>92.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5590868</td>\n",
       "<td>0.8098958</td>\n",
       "<td>153.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9992004</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0100612</td>\n",
       "<td>1.0</td>\n",
       "<td>386.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9992004</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4403612</td>\n",
       "<td>0.5923963</td>\n",
       "<td>187.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4082299</td>\n",
       "<td>0.79</td>\n",
       "<td>201.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3594237</td>\n",
       "<td>0.8023731</td>\n",
       "<td>222.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.440361     0.740214  187\n",
       "max f2                       0.22584      0.827267  274\n",
       "max f0point5                 0.740716     0.742925  92\n",
       "max accuracy                 0.559087     0.809896  153\n",
       "max precision                0.9992       1         0\n",
       "max recall                   0.0100612    1         386\n",
       "max specificity              0.9992       1         0\n",
       "max absolute_mcc             0.440361     0.592396  187\n",
       "max min_per_class_accuracy   0.40823      0.79      201\n",
       "max mean_per_class_accuracy  0.359424     0.802373  222"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 34.90 %, avg score: 37.47 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0104167</td>\n",
       "<td>0.9935929</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969018</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9969018</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0298507</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.9906451</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9919497</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9944258</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0597015</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03125</td>\n",
       "<td>0.9799905</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9859181</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9915899</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0895522</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0403646</td>\n",
       "<td>0.9652770</td>\n",
       "<td>2.4562900</td>\n",
       "<td>2.7732306</td>\n",
       "<td>0.8571429</td>\n",
       "<td>0.9718290</td>\n",
       "<td>0.9677419</td>\n",
       "<td>0.9871277</td>\n",
       "<td>0.0223881</td>\n",
       "<td>0.1119403</td>\n",
       "<td>145.6289979</td>\n",
       "<td>177.3230621</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0507812</td>\n",
       "<td>0.9568134</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.7921929</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9619678</td>\n",
       "<td>0.9743590</td>\n",
       "<td>0.9819667</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.1417910</td>\n",
       "<td>186.5671642</td>\n",
       "<td>179.2192882</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1002604</td>\n",
       "<td>0.8817798</td>\n",
       "<td>2.5640220</td>\n",
       "<td>2.6795891</td>\n",
       "<td>0.8947368</td>\n",
       "<td>0.9200499</td>\n",
       "<td>0.9350649</td>\n",
       "<td>0.9514104</td>\n",
       "<td>0.1268657</td>\n",
       "<td>0.2686567</td>\n",
       "<td>156.4021995</td>\n",
       "<td>167.9589068</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1510417</td>\n",
       "<td>0.8034251</td>\n",
       "<td>2.4247991</td>\n",
       "<td>2.5939269</td>\n",
       "<td>0.8461538</td>\n",
       "<td>0.8410573</td>\n",
       "<td>0.9051724</td>\n",
       "<td>0.9143089</td>\n",
       "<td>0.1231343</td>\n",
       "<td>0.3917910</td>\n",
       "<td>142.4799082</td>\n",
       "<td>159.3926917</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2005208</td>\n",
       "<td>0.7246150</td>\n",
       "<td>1.7344855</td>\n",
       "<td>2.3818569</td>\n",
       "<td>0.6052632</td>\n",
       "<td>0.7612742</td>\n",
       "<td>0.8311688</td>\n",
       "<td>0.8765471</td>\n",
       "<td>0.0858209</td>\n",
       "<td>0.4776119</td>\n",
       "<td>73.4485467</td>\n",
       "<td>138.1856949</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3007812</td>\n",
       "<td>0.5738435</td>\n",
       "<td>1.6747432</td>\n",
       "<td>2.1461524</td>\n",
       "<td>0.5844156</td>\n",
       "<td>0.6475050</td>\n",
       "<td>0.7489177</td>\n",
       "<td>0.8001997</td>\n",
       "<td>0.1679104</td>\n",
       "<td>0.6455224</td>\n",
       "<td>67.4743167</td>\n",
       "<td>114.6152355</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3997396</td>\n",
       "<td>0.4184800</td>\n",
       "<td>1.3951296</td>\n",
       "<td>1.9602314</td>\n",
       "<td>0.4868421</td>\n",
       "<td>0.4923384</td>\n",
       "<td>0.6840391</td>\n",
       "<td>0.7239865</td>\n",
       "<td>0.1380597</td>\n",
       "<td>0.7835821</td>\n",
       "<td>39.5129615</td>\n",
       "<td>96.0231416</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.3022449</td>\n",
       "<td>0.9304129</td>\n",
       "<td>1.7537313</td>\n",
       "<td>0.3246753</td>\n",
       "<td>0.3627552</td>\n",
       "<td>0.6119792</td>\n",
       "<td>0.6515521</td>\n",
       "<td>0.0932836</td>\n",
       "<td>0.8768657</td>\n",
       "<td>-6.9587129</td>\n",
       "<td>75.3731343</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6002604</td>\n",
       "<td>0.1994752</td>\n",
       "<td>0.6326808</td>\n",
       "<td>1.5664843</td>\n",
       "<td>0.2207792</td>\n",
       "<td>0.2503017</td>\n",
       "<td>0.5466377</td>\n",
       "<td>0.5845320</td>\n",
       "<td>0.0634328</td>\n",
       "<td>0.9402985</td>\n",
       "<td>-36.7319248</td>\n",
       "<td>56.6484281</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6992188</td>\n",
       "<td>0.1013256</td>\n",
       "<td>0.3393559</td>\n",
       "<td>1.3928125</td>\n",
       "<td>0.1184211</td>\n",
       "<td>0.1541834</td>\n",
       "<td>0.4860335</td>\n",
       "<td>0.5236260</td>\n",
       "<td>0.0335821</td>\n",
       "<td>0.9738806</td>\n",
       "<td>-66.0644148</td>\n",
       "<td>39.2812474</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7994792</td>\n",
       "<td>0.0349224</td>\n",
       "<td>0.1488661</td>\n",
       "<td>1.2368127</td>\n",
       "<td>0.0519481</td>\n",
       "<td>0.0664056</td>\n",
       "<td>0.4315961</td>\n",
       "<td>0.4662873</td>\n",
       "<td>0.0149254</td>\n",
       "<td>0.9888060</td>\n",
       "<td>-85.1133941</td>\n",
       "<td>23.6812679</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8997396</td>\n",
       "<td>0.0062193</td>\n",
       "<td>0.1116495</td>\n",
       "<td>1.1114327</td>\n",
       "<td>0.0389610</td>\n",
       "<td>0.0175148</td>\n",
       "<td>0.3878437</td>\n",
       "<td>0.4162794</td>\n",
       "<td>0.0111940</td>\n",
       "<td>1.0</td>\n",
       "<td>-88.8350456</td>\n",
       "<td>11.1432706</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001778</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0019331</td>\n",
       "<td>0.3489583</td>\n",
       "<td>0.3747368</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0104167                   0.993593           2.86567   2.86567            1                0.996902    1                           0.996902            0.0298507       0.0298507                  186.567   186.567\n",
       "    2        0.0208333                   0.990645           2.86567   2.86567            1                0.99195     1                           0.994426            0.0298507       0.0597015                  186.567   186.567\n",
       "    3        0.03125                     0.979991           2.86567   2.86567            1                0.985918    1                           0.99159             0.0298507       0.0895522                  186.567   186.567\n",
       "    4        0.0403646                   0.965277           2.45629   2.77323            0.857143         0.971829    0.967742                    0.987128            0.0223881       0.11194                    145.629   177.323\n",
       "    5        0.0507812                   0.956813           2.86567   2.79219            1                0.961968    0.974359                    0.981967            0.0298507       0.141791                   186.567   179.219\n",
       "    6        0.10026                     0.88178            2.56402   2.67959            0.894737         0.92005     0.935065                    0.95141             0.126866        0.268657                   156.402   167.959\n",
       "    7        0.151042                    0.803425           2.4248    2.59393            0.846154         0.841057    0.905172                    0.914309            0.123134        0.391791                   142.48    159.393\n",
       "    8        0.200521                    0.724615           1.73449   2.38186            0.605263         0.761274    0.831169                    0.876547            0.0858209       0.477612                   73.4485   138.186\n",
       "    9        0.300781                    0.573843           1.67474   2.14615            0.584416         0.647505    0.748918                    0.8002              0.16791         0.645522                   67.4743   114.615\n",
       "    10       0.39974                     0.41848            1.39513   1.96023            0.486842         0.492338    0.684039                    0.723987            0.13806         0.783582                   39.513    96.0231\n",
       "    11       0.5                         0.302245           0.930413  1.75373            0.324675         0.362755    0.611979                    0.651552            0.0932836       0.876866                   -6.95871  75.3731\n",
       "    12       0.60026                     0.199475           0.632681  1.56648            0.220779         0.250302    0.546638                    0.584532            0.0634328       0.940299                   -36.7319  56.6484\n",
       "    13       0.699219                    0.101326           0.339356  1.39281            0.118421         0.154183    0.486034                    0.523626            0.0335821       0.973881                   -66.0644  39.2812\n",
       "    14       0.799479                    0.0349224          0.148866  1.23681            0.0519481        0.0664056   0.431596                    0.466287            0.0149254       0.988806                   -85.1134  23.6813\n",
       "    15       0.89974                     0.00621927         0.11165   1.11143            0.038961         0.0175148   0.387844                    0.416279            0.011194        1                          -88.835   11.1433\n",
       "    16       1                           0.000177794        0         1                  0                0.00193308  0.348958                    0.374737            0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_model.model_performance(diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "dl_model1 = H2ODeepLearningEstimator(hidden=[20,20,20],epochs=500,nfolds=10)\n",
    "dl_model1.train(myx, myy, training_frame=diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_model_python_1556030189279_177\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.04007000999046607\n",
      "RMSE: 0.2001749484587571\n",
      "LogLoss: 0.13035578501037348\n",
      "Mean Per-Class Error: 0.05092537313432832\n",
      "AUC: 0.9904701492537314\n",
      "pr_auc: 0.8190900163776056\n",
      "Gini: 0.9809402985074629\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.6787572484692351: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>481.0</td>\n",
       "<td>19.0</td>\n",
       "<td>0.038</td>\n",
       "<td> (19.0/500.0)</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>19.0</td>\n",
       "<td>249.0</td>\n",
       "<td>0.0709</td>\n",
       "<td> (19.0/268.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>500.0</td>\n",
       "<td>268.0</td>\n",
       "<td>0.0495</td>\n",
       "<td> (38.0/768.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       1    2    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "1      481  19   0.038    (19.0/500.0)\n",
       "2      19   249  0.0709   (19.0/268.0)\n",
       "Total  500  268  0.0495   (38.0/768.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.6787572</td>\n",
       "<td>0.9291045</td>\n",
       "<td>155.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2473549</td>\n",
       "<td>0.9546110</td>\n",
       "<td>203.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.8692058</td>\n",
       "<td>0.9457237</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7108938</td>\n",
       "<td>0.9505208</td>\n",
       "<td>151.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999992</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0245851</td>\n",
       "<td>1.0</td>\n",
       "<td>285.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999992</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6787572</td>\n",
       "<td>0.8911045</td>\n",
       "<td>155.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.5612397</td>\n",
       "<td>0.9402985</td>\n",
       "<td>168.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4196769</td>\n",
       "<td>0.9490746</td>\n",
       "<td>183.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.678757     0.929104  155\n",
       "max f2                       0.247355     0.954611  203\n",
       "max f0point5                 0.869206     0.945724  124\n",
       "max accuracy                 0.710894     0.950521  151\n",
       "max precision                0.999999     1         0\n",
       "max recall                   0.0245851    1         285\n",
       "max specificity              0.999999     1         0\n",
       "max absolute_mcc             0.678757     0.891104  155\n",
       "max min_per_class_accuracy   0.56124      0.940299  168\n",
       "max mean_per_class_accuracy  0.419677     0.949075  183"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 34.90 %, avg score: 37.54 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0104167</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0298507</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0208333</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0597015</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03125</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0895522</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0403646</td>\n",
       "<td>0.9999995</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999998</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0261194</td>\n",
       "<td>0.1156716</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0507812</td>\n",
       "<td>0.9999970</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999988</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999997</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.1455224</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1002604</td>\n",
       "<td>0.9998034</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999380</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999693</td>\n",
       "<td>0.1417910</td>\n",
       "<td>0.2873134</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1510417</td>\n",
       "<td>0.9982842</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9991913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9997077</td>\n",
       "<td>0.1455224</td>\n",
       "<td>0.4328358</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2005208</td>\n",
       "<td>0.9943498</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9964991</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9989160</td>\n",
       "<td>0.1417910</td>\n",
       "<td>0.5746269</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3007812</td>\n",
       "<td>0.8878527</td>\n",
       "<td>2.6051560</td>\n",
       "<td>2.7788331</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.9683456</td>\n",
       "<td>0.9696970</td>\n",
       "<td>0.9887259</td>\n",
       "<td>0.2611940</td>\n",
       "<td>0.8358209</td>\n",
       "<td>160.5156038</td>\n",
       "<td>177.8833107</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3997396</td>\n",
       "<td>0.3023350</td>\n",
       "<td>1.4328358</td>\n",
       "<td>2.4456221</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6387442</td>\n",
       "<td>0.8534202</td>\n",
       "<td>0.9020855</td>\n",
       "<td>0.1417910</td>\n",
       "<td>0.9776119</td>\n",
       "<td>43.2835821</td>\n",
       "<td>144.5622053</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0348632</td>\n",
       "<td>0.1860826</td>\n",
       "<td>1.9925373</td>\n",
       "<td>0.0649351</td>\n",
       "<td>0.1284766</td>\n",
       "<td>0.6953125</td>\n",
       "<td>0.7469608</td>\n",
       "<td>0.0186567</td>\n",
       "<td>0.9962687</td>\n",
       "<td>-81.3917426</td>\n",
       "<td>99.2537313</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6002604</td>\n",
       "<td>0.0058288</td>\n",
       "<td>0.0372165</td>\n",
       "<td>1.6659436</td>\n",
       "<td>0.0129870</td>\n",
       "<td>0.0157336</td>\n",
       "<td>0.5813449</td>\n",
       "<td>0.6248252</td>\n",
       "<td>0.0037313</td>\n",
       "<td>1.0</td>\n",
       "<td>-96.2783485</td>\n",
       "<td>66.5943601</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6992188</td>\n",
       "<td>0.0009436</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4301676</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0027128</td>\n",
       "<td>0.4990689</td>\n",
       "<td>0.5367795</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.0167598</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7994792</td>\n",
       "<td>0.0000382</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2508143</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0003676</td>\n",
       "<td>0.4364821</td>\n",
       "<td>0.4695096</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0814332</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8997396</td>\n",
       "<td>0.0000004</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1114327</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000089</td>\n",
       "<td>0.3878437</td>\n",
       "<td>0.4171919</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1432706</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.3489583</td>\n",
       "<td>0.3753640</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0104167                   1                  2.86567    2.86567            1                1            1                           1                   0.0298507       0.0298507                  186.567   186.567\n",
       "    2        0.0208333                   1                  2.86567    2.86567            1                1            1                           1                   0.0298507       0.0597015                  186.567   186.567\n",
       "    3        0.03125                     1                  2.86567    2.86567            1                1            1                           1                   0.0298507       0.0895522                  186.567   186.567\n",
       "    4        0.0403646                   1                  2.86567    2.86567            1                1            1                           1                   0.0261194       0.115672                   186.567   186.567\n",
       "    5        0.0507812                   0.999997           2.86567    2.86567            1                0.999999     1                           1                   0.0298507       0.145522                   186.567   186.567\n",
       "    6        0.10026                     0.999803           2.86567    2.86567            1                0.999938     1                           0.999969            0.141791        0.287313                   186.567   186.567\n",
       "    7        0.151042                    0.998284           2.86567    2.86567            1                0.999191     1                           0.999708            0.145522        0.432836                   186.567   186.567\n",
       "    8        0.200521                    0.99435            2.86567    2.86567            1                0.996499     1                           0.998916            0.141791        0.574627                   186.567   186.567\n",
       "    9        0.300781                    0.887853           2.60516    2.77883            0.909091         0.968346     0.969697                    0.988726            0.261194        0.835821                   160.516   177.883\n",
       "    10       0.39974                     0.302335           1.43284    2.44562            0.5              0.638744     0.85342                     0.902085            0.141791        0.977612                   43.2836   144.562\n",
       "    11       0.5                         0.0348632          0.186083   1.99254            0.0649351        0.128477     0.695312                    0.746961            0.0186567       0.996269                   -81.3917  99.2537\n",
       "    12       0.60026                     0.00582882         0.0372165  1.66594            0.012987         0.0157336    0.581345                    0.624825            0.00373134      1                          -96.2783  66.5944\n",
       "    13       0.699219                    0.000943603        0          1.43017            0                0.00271278   0.499069                    0.53678             0               1                          -100      43.0168\n",
       "    14       0.799479                    3.8184e-05         0          1.25081            0                0.000367567  0.436482                    0.46951             0               1                          -100      25.0814\n",
       "    15       0.89974                     4.31943e-07        0          1.11143            0                8.87668e-06  0.387844                    0.417192            0               1                          -100      11.1433\n",
       "    16       1                           2.41562e-19        0          1                  0                5.67885e-08  0.348958                    0.375364            0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.20479737060337302\n",
      "RMSE: 0.45254543484977616\n",
      "LogLoss: 0.6392566263634363\n",
      "Mean Per-Class Error: 0.2914477611940298\n",
      "AUC: 0.7686007462686567\n",
      "pr_auc: 0.6259658793292818\n",
      "Gini: 0.5372014925373134\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.46626185912342266: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>348.0</td>\n",
       "<td>152.0</td>\n",
       "<td>0.304</td>\n",
       "<td> (152.0/500.0)</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>76.0</td>\n",
       "<td>192.0</td>\n",
       "<td>0.2836</td>\n",
       "<td> (76.0/268.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>424.0</td>\n",
       "<td>344.0</td>\n",
       "<td>0.2969</td>\n",
       "<td> (228.0/768.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       1    2    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "1      348  152  0.304    (152.0/500.0)\n",
       "2      76   192  0.2836   (76.0/268.0)\n",
       "Total  424  344  0.2969   (228.0/768.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4662619</td>\n",
       "<td>0.6274510</td>\n",
       "<td>194.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1497894</td>\n",
       "<td>0.7574832</td>\n",
       "<td>315.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6704128</td>\n",
       "<td>0.6148867</td>\n",
       "<td>132.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6722274</td>\n",
       "<td>0.7317708</td>\n",
       "<td>131.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9960157</td>\n",
       "<td>0.9166667</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0242549</td>\n",
       "<td>1.0</td>\n",
       "<td>385.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9994818</td>\n",
       "<td>0.998</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5898522</td>\n",
       "<td>0.4057339</td>\n",
       "<td>157.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4851209</td>\n",
       "<td>0.7014925</td>\n",
       "<td>188.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.5161696</td>\n",
       "<td>0.7085522</td>\n",
       "<td>176.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.466262     0.627451  194\n",
       "max f2                       0.149789     0.757483  315\n",
       "max f0point5                 0.670413     0.614887  132\n",
       "max accuracy                 0.672227     0.731771  131\n",
       "max precision                0.996016     0.916667  3\n",
       "max recall                   0.0242549    1         385\n",
       "max specificity              0.999482     0.998     0\n",
       "max absolute_mcc             0.589852     0.405734  157\n",
       "max min_per_class_accuracy   0.485121     0.701493  188\n",
       "max mean_per_class_accuracy  0.51617      0.708552  176"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 34.90 %, avg score: 44.64 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0104167</td>\n",
       "<td>0.9976063</td>\n",
       "<td>2.5074627</td>\n",
       "<td>2.5074627</td>\n",
       "<td>0.875</td>\n",
       "<td>0.9988821</td>\n",
       "<td>0.875</td>\n",
       "<td>0.9988821</td>\n",
       "<td>0.0261194</td>\n",
       "<td>0.0261194</td>\n",
       "<td>150.7462687</td>\n",
       "<td>150.7462687</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.9945723</td>\n",
       "<td>2.5074627</td>\n",
       "<td>2.5074627</td>\n",
       "<td>0.875</td>\n",
       "<td>0.9960138</td>\n",
       "<td>0.875</td>\n",
       "<td>0.9974480</td>\n",
       "<td>0.0261194</td>\n",
       "<td>0.0522388</td>\n",
       "<td>150.7462687</td>\n",
       "<td>150.7462687</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03125</td>\n",
       "<td>0.9885229</td>\n",
       "<td>2.5074627</td>\n",
       "<td>2.5074627</td>\n",
       "<td>0.875</td>\n",
       "<td>0.9914667</td>\n",
       "<td>0.875</td>\n",
       "<td>0.9954542</td>\n",
       "<td>0.0261194</td>\n",
       "<td>0.0783582</td>\n",
       "<td>150.7462687</td>\n",
       "<td>150.7462687</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0403646</td>\n",
       "<td>0.9827184</td>\n",
       "<td>2.0469083</td>\n",
       "<td>2.4034665</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.9853992</td>\n",
       "<td>0.8387097</td>\n",
       "<td>0.9931837</td>\n",
       "<td>0.0186567</td>\n",
       "<td>0.0970149</td>\n",
       "<td>104.6908316</td>\n",
       "<td>140.3466538</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0507812</td>\n",
       "<td>0.9767499</td>\n",
       "<td>2.1492537</td>\n",
       "<td>2.3513203</td>\n",
       "<td>0.75</td>\n",
       "<td>0.9799981</td>\n",
       "<td>0.8205128</td>\n",
       "<td>0.9904790</td>\n",
       "<td>0.0223881</td>\n",
       "<td>0.1194030</td>\n",
       "<td>114.9253731</td>\n",
       "<td>135.1320321</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1002604</td>\n",
       "<td>0.9479819</td>\n",
       "<td>1.8853103</td>\n",
       "<td>2.1213413</td>\n",
       "<td>0.6578947</td>\n",
       "<td>0.9628919</td>\n",
       "<td>0.7402597</td>\n",
       "<td>0.9768646</td>\n",
       "<td>0.0932836</td>\n",
       "<td>0.2126866</td>\n",
       "<td>88.5310291</td>\n",
       "<td>112.1341345</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1510417</td>\n",
       "<td>0.8779989</td>\n",
       "<td>1.6165327</td>\n",
       "<td>1.9516212</td>\n",
       "<td>0.5641026</td>\n",
       "<td>0.9184726</td>\n",
       "<td>0.6810345</td>\n",
       "<td>0.9572328</td>\n",
       "<td>0.0820896</td>\n",
       "<td>0.2947761</td>\n",
       "<td>61.6532721</td>\n",
       "<td>95.1621204</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2005208</td>\n",
       "<td>0.8184740</td>\n",
       "<td>1.9607227</td>\n",
       "<td>1.9538670</td>\n",
       "<td>0.6842105</td>\n",
       "<td>0.8459221</td>\n",
       "<td>0.6818182</td>\n",
       "<td>0.9297665</td>\n",
       "<td>0.0970149</td>\n",
       "<td>0.3917910</td>\n",
       "<td>96.0722702</td>\n",
       "<td>95.3867028</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3007812</td>\n",
       "<td>0.6868366</td>\n",
       "<td>1.5258771</td>\n",
       "<td>1.8112037</td>\n",
       "<td>0.5324675</td>\n",
       "<td>0.7481042</td>\n",
       "<td>0.6320346</td>\n",
       "<td>0.8692124</td>\n",
       "<td>0.1529851</td>\n",
       "<td>0.5447761</td>\n",
       "<td>52.5877108</td>\n",
       "<td>81.1203722</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3997396</td>\n",
       "<td>0.5225621</td>\n",
       "<td>1.2065986</td>\n",
       "<td>1.6615295</td>\n",
       "<td>0.4210526</td>\n",
       "<td>0.6125569</td>\n",
       "<td>0.5798046</td>\n",
       "<td>0.8056755</td>\n",
       "<td>0.1194030</td>\n",
       "<td>0.6641791</td>\n",
       "<td>20.6598586</td>\n",
       "<td>66.1529486</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.3912137</td>\n",
       "<td>0.9304129</td>\n",
       "<td>1.5149254</td>\n",
       "<td>0.3246753</td>\n",
       "<td>0.4587849</td>\n",
       "<td>0.5286458</td>\n",
       "<td>0.7361167</td>\n",
       "<td>0.0932836</td>\n",
       "<td>0.7574627</td>\n",
       "<td>-6.9587129</td>\n",
       "<td>51.4925373</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6002604</td>\n",
       "<td>0.2723941</td>\n",
       "<td>0.8931964</td>\n",
       "<td>1.4110791</td>\n",
       "<td>0.3116883</td>\n",
       "<td>0.3266718</td>\n",
       "<td>0.4924078</td>\n",
       "<td>0.6677279</td>\n",
       "<td>0.0895522</td>\n",
       "<td>0.8470149</td>\n",
       "<td>-10.6803644</td>\n",
       "<td>41.1079095</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6992188</td>\n",
       "<td>0.1826407</td>\n",
       "<td>0.5278869</td>\n",
       "<td>1.2860835</td>\n",
       "<td>0.1842105</td>\n",
       "<td>0.2249121</td>\n",
       "<td>0.4487896</td>\n",
       "<td>0.6050575</td>\n",
       "<td>0.0522388</td>\n",
       "<td>0.8992537</td>\n",
       "<td>-47.2113119</td>\n",
       "<td>28.6083549</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7994792</td>\n",
       "<td>0.0945024</td>\n",
       "<td>0.4093817</td>\n",
       "<td>1.1761388</td>\n",
       "<td>0.1428571</td>\n",
       "<td>0.1383386</td>\n",
       "<td>0.4104235</td>\n",
       "<td>0.5465276</td>\n",
       "<td>0.0410448</td>\n",
       "<td>0.9402985</td>\n",
       "<td>-59.0618337</td>\n",
       "<td>17.6138850</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8997396</td>\n",
       "<td>0.0452412</td>\n",
       "<td>0.3349486</td>\n",
       "<td>1.0824027</td>\n",
       "<td>0.1168831</td>\n",
       "<td>0.0683806</td>\n",
       "<td>0.3777135</td>\n",
       "<td>0.4932464</td>\n",
       "<td>0.0335821</td>\n",
       "<td>0.9738806</td>\n",
       "<td>-66.5051367</td>\n",
       "<td>8.2402747</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0005067</td>\n",
       "<td>0.2605156</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0909091</td>\n",
       "<td>0.0256116</td>\n",
       "<td>0.3489583</td>\n",
       "<td>0.4463611</td>\n",
       "<td>0.0261194</td>\n",
       "<td>1.0</td>\n",
       "<td>-73.9484396</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0104167                   0.997606           2.50746   2.50746            0.875            0.998882   0.875                       0.998882            0.0261194       0.0261194                  150.746   150.746\n",
       "    2        0.0208333                   0.994572           2.50746   2.50746            0.875            0.996014   0.875                       0.997448            0.0261194       0.0522388                  150.746   150.746\n",
       "    3        0.03125                     0.988523           2.50746   2.50746            0.875            0.991467   0.875                       0.995454            0.0261194       0.0783582                  150.746   150.746\n",
       "    4        0.0403646                   0.982718           2.04691   2.40347            0.714286         0.985399   0.83871                     0.993184            0.0186567       0.0970149                  104.691   140.347\n",
       "    5        0.0507812                   0.97675            2.14925   2.35132            0.75             0.979998   0.820513                    0.990479            0.0223881       0.119403                   114.925   135.132\n",
       "    6        0.10026                     0.947982           1.88531   2.12134            0.657895         0.962892   0.74026                     0.976865            0.0932836       0.212687                   88.531    112.134\n",
       "    7        0.151042                    0.877999           1.61653   1.95162            0.564103         0.918473   0.681034                    0.957233            0.0820896       0.294776                   61.6533   95.1621\n",
       "    8        0.200521                    0.818474           1.96072   1.95387            0.684211         0.845922   0.681818                    0.929767            0.0970149       0.391791                   96.0723   95.3867\n",
       "    9        0.300781                    0.686837           1.52588   1.8112             0.532468         0.748104   0.632035                    0.869212            0.152985        0.544776                   52.5877   81.1204\n",
       "    10       0.39974                     0.522562           1.2066    1.66153            0.421053         0.612557   0.579805                    0.805676            0.119403        0.664179                   20.6599   66.1529\n",
       "    11       0.5                         0.391214           0.930413  1.51493            0.324675         0.458785   0.528646                    0.736117            0.0932836       0.757463                   -6.95871  51.4925\n",
       "    12       0.60026                     0.272394           0.893196  1.41108            0.311688         0.326672   0.492408                    0.667728            0.0895522       0.847015                   -10.6804  41.1079\n",
       "    13       0.699219                    0.182641           0.527887  1.28608            0.184211         0.224912   0.44879                     0.605057            0.0522388       0.899254                   -47.2113  28.6084\n",
       "    14       0.799479                    0.0945024          0.409382  1.17614            0.142857         0.138339   0.410423                    0.546528            0.0410448       0.940299                   -59.0618  17.6139\n",
       "    15       0.89974                     0.0452412          0.334949  1.0824             0.116883         0.0683806  0.377713                    0.493246            0.0335821       0.973881                   -66.5051  8.24027\n",
       "    16       1                           0.000506673        0.260516  1                  0.0909091        0.0256116  0.348958                    0.446361            0.0261194       1                          -73.9484  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td>\n",
       "<td><b>cv_6_valid</b></td>\n",
       "<td><b>cv_7_valid</b></td>\n",
       "<td><b>cv_8_valid</b></td>\n",
       "<td><b>cv_9_valid</b></td>\n",
       "<td><b>cv_10_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.7183492</td>\n",
       "<td>0.0826223</td>\n",
       "<td>0.76</td>\n",
       "<td>0.7582418</td>\n",
       "<td>0.7432432</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.6582279</td>\n",
       "<td>0.7849463</td>\n",
       "<td>0.4029851</td>\n",
       "<td>0.8253968</td>\n",
       "<td>0.7837838</td>\n",
       "<td>0.8</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.7729259</td>\n",
       "<td>0.0479610</td>\n",
       "<td>0.8273156</td>\n",
       "<td>0.8207942</td>\n",
       "<td>0.7655172</td>\n",
       "<td>0.7903846</td>\n",
       "<td>0.7576197</td>\n",
       "<td>0.8248804</td>\n",
       "<td>0.5842593</td>\n",
       "<td>0.7583121</td>\n",
       "<td>0.8095238</td>\n",
       "<td>0.7906517</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.2816509</td>\n",
       "<td>0.0826223</td>\n",
       "<td>0.24</td>\n",
       "<td>0.2417582</td>\n",
       "<td>0.2567567</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.3417721</td>\n",
       "<td>0.2150538</td>\n",
       "<td>0.5970149</td>\n",
       "<td>0.1746032</td>\n",
       "<td>0.2162162</td>\n",
       "<td>0.2</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>21.3</td>\n",
       "<td>5.3390074</td>\n",
       "<td>18.0</td>\n",
       "<td>22.0</td>\n",
       "<td>19.0</td>\n",
       "<td>24.0</td>\n",
       "<td>27.0</td>\n",
       "<td>20.0</td>\n",
       "<td>40.0</td>\n",
       "<td>11.0</td>\n",
       "<td>16.0</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.6243012</td>\n",
       "<td>0.0653106</td>\n",
       "<td>0.6470588</td>\n",
       "<td>0.6530612</td>\n",
       "<td>0.6629834</td>\n",
       "<td>0.4941860</td>\n",
       "<td>0.5373832</td>\n",
       "<td>0.7323232</td>\n",
       "<td>0.4576271</td>\n",
       "<td>0.7017544</td>\n",
       "<td>0.620438</td>\n",
       "<td>0.7361963</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.6727276</td>\n",
       "<td>0.0473298</td>\n",
       "<td>0.7096774</td>\n",
       "<td>0.7441860</td>\n",
       "<td>0.7164179</td>\n",
       "<td>0.5862069</td>\n",
       "<td>0.6301370</td>\n",
       "<td>0.7435898</td>\n",
       "<td>0.5744681</td>\n",
       "<td>0.5925926</td>\n",
       "<td>0.68</td>\n",
       "<td>0.75</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.7467729</td>\n",
       "<td>0.0604913</td>\n",
       "<td>0.7857143</td>\n",
       "<td>0.8648649</td>\n",
       "<td>0.7792208</td>\n",
       "<td>0.720339</td>\n",
       "<td>0.7615894</td>\n",
       "<td>0.7552083</td>\n",
       "<td>0.7714286</td>\n",
       "<td>0.5128205</td>\n",
       "<td>0.7522124</td>\n",
       "<td>0.7643312</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.7124195</td>\n",
       "<td>0.707985</td>\n",
       "<td>2.8846154</td>\n",
       "<td>2.7575758</td>\n",
       "<td>2.5517242</td>\n",
       "<td>3.6</td>\n",
       "<td>3.0384614</td>\n",
       "<td>0.0</td>\n",
       "<td>2.4814816</td>\n",
       "<td>3.7058823</td>\n",
       "<td>3.5238094</td>\n",
       "<td>2.580645</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.6412017</td>\n",
       "<td>0.0716988</td>\n",
       "<td>0.5445455</td>\n",
       "<td>0.5497806</td>\n",
       "<td>0.6369638</td>\n",
       "<td>0.8288559</td>\n",
       "<td>0.5711256</td>\n",
       "<td>0.7244759</td>\n",
       "<td>0.7938169</td>\n",
       "<td>0.603239</td>\n",
       "<td>0.5261444</td>\n",
       "<td>0.6330693</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.4034046</td>\n",
       "<td>0.1563544</td>\n",
       "<td>0.2857143</td>\n",
       "<td>0.3620690</td>\n",
       "<td>0.3111111</td>\n",
       "<td>0.4038461</td>\n",
       "<td>0.4528302</td>\n",
       "<td>0.2368421</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.2264151</td>\n",
       "<td>0.2258064</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.5161238</td>\n",
       "<td>0.0525454</td>\n",
       "<td>0.5338631</td>\n",
       "<td>0.5923508</td>\n",
       "<td>0.5044424</td>\n",
       "<td>0.4002857</td>\n",
       "<td>0.4133029</td>\n",
       "<td>0.5591591</td>\n",
       "<td>NaN</td>\n",
       "<td>0.5188062</td>\n",
       "<td>0.5385076</td>\n",
       "<td>0.5843965</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.7363190</td>\n",
       "<td>0.0602056</td>\n",
       "<td>0.7802198</td>\n",
       "<td>0.803814</td>\n",
       "<td>0.7582375</td>\n",
       "<td>0.7230769</td>\n",
       "<td>0.7158926</td>\n",
       "<td>0.7815790</td>\n",
       "<td>0.5</td>\n",
       "<td>0.713555</td>\n",
       "<td>0.7915543</td>\n",
       "<td>0.79526</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.2636811</td>\n",
       "<td>0.0602056</td>\n",
       "<td>0.2197802</td>\n",
       "<td>0.1961860</td>\n",
       "<td>0.2417625</td>\n",
       "<td>0.2769231</td>\n",
       "<td>0.2841074</td>\n",
       "<td>0.2184211</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2864450</td>\n",
       "<td>0.2084456</td>\n",
       "<td>0.2047400</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.2062107</td>\n",
       "<td>0.0226852</td>\n",
       "<td>0.1797632</td>\n",
       "<td>0.1750896</td>\n",
       "<td>0.1975133</td>\n",
       "<td>0.2673989</td>\n",
       "<td>0.1922146</td>\n",
       "<td>0.2099520</td>\n",
       "<td>0.2627522</td>\n",
       "<td>0.2055645</td>\n",
       "<td>0.1689766</td>\n",
       "<td>0.2028821</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.6024659</td>\n",
       "<td>0.0858603</td>\n",
       "<td>0.6111111</td>\n",
       "<td>0.6037736</td>\n",
       "<td>0.6315789</td>\n",
       "<td>0.4473684</td>\n",
       "<td>0.4893617</td>\n",
       "<td>0.725</td>\n",
       "<td>0.4029851</td>\n",
       "<td>0.8</td>\n",
       "<td>0.5862069</td>\n",
       "<td>0.7272728</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.0726078</td>\n",
       "<td>0.1188690</td>\n",
       "<td>0.2063047</td>\n",
       "<td>0.2424678</td>\n",
       "<td>0.1712009</td>\n",
       "<td>-0.3328807</td>\n",
       "<td>0.1294550</td>\n",
       "<td>0.1311602</td>\n",
       "<td>-0.0921247</td>\n",
       "<td>-0.0433320</td>\n",
       "<td>0.1686291</td>\n",
       "<td>0.1451971</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.8195516</td>\n",
       "<td>0.0969926</td>\n",
       "<td>0.8461539</td>\n",
       "<td>0.969697</td>\n",
       "<td>0.8275862</td>\n",
       "<td>0.85</td>\n",
       "<td>0.8846154</td>\n",
       "<td>0.7631579</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4705882</td>\n",
       "<td>0.8095238</td>\n",
       "<td>0.7741935</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.4528059</td>\n",
       "<td>0.0242645</td>\n",
       "<td>0.4239849</td>\n",
       "<td>0.4184370</td>\n",
       "<td>0.4444247</td>\n",
       "<td>0.5171063</td>\n",
       "<td>0.4384228</td>\n",
       "<td>0.4582052</td>\n",
       "<td>0.5125936</td>\n",
       "<td>0.4533922</td>\n",
       "<td>0.4110676</td>\n",
       "<td>0.4504244</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.6530862</td>\n",
       "<td>0.1733583</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.6379311</td>\n",
       "<td>0.6888889</td>\n",
       "<td>0.5961539</td>\n",
       "<td>0.5471698</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9565217</td>\n",
       "<td>0.7735849</td>\n",
       "<td>0.8163266</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
       "-----------------------  ---------  ---------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
       "accuracy                 0.718349   0.0826223  0.76          0.758242      0.743243      0.666667      0.658228      0.784946      0.402985      0.825397      0.783784      0.8\n",
       "auc                      0.772926   0.047961   0.827316      0.820794      0.765517      0.790385      0.75762       0.82488       0.584259      0.758312      0.809524      0.790652\n",
       "err                      0.281651   0.0826223  0.24          0.241758      0.256757      0.333333      0.341772      0.215054      0.597015      0.174603      0.216216      0.2\n",
       "err_count                21.3       5.33901    18            22            19            24            27            20            40            11            16            16\n",
       "f0point5                 0.624301   0.0653106  0.647059      0.653061      0.662983      0.494186      0.537383      0.732323      0.457627      0.701754      0.620438      0.736196\n",
       "f1                       0.672728   0.0473298  0.709677      0.744186      0.716418      0.586207      0.630137      0.74359       0.574468      0.592593      0.68          0.75\n",
       "f2                       0.746773   0.0604913  0.785714      0.864865      0.779221      0.720339      0.761589      0.755208      0.771429      0.512821      0.752212      0.764331\n",
       "lift_top_group           2.71242    0.707985   2.88462       2.75758       2.55172       3.6           3.03846       0             2.48148       3.70588       3.52381       2.58065\n",
       "logloss                  0.641202   0.0716988  0.544546      0.549781      0.636964      0.828856      0.571126      0.724476      0.793817      0.603239      0.526144      0.633069\n",
       "max_per_class_error      0.403405   0.156354   0.285714      0.362069      0.311111      0.403846      0.45283       0.236842      1             0.529412      0.226415      0.225806\n",
       "mcc                      0.516124   0.0525454  0.533863      0.592351      0.504442      0.400286      0.413303      0.559159      nan           0.518806      0.538508      0.584397\n",
       "mean_per_class_accuracy  0.736319   0.0602056  0.78022       0.803814      0.758238      0.723077      0.715893      0.781579      0.5           0.713555      0.791554      0.79526\n",
       "mean_per_class_error     0.263681   0.0602056  0.21978       0.196186      0.241762      0.276923      0.284107      0.218421      0.5           0.286445      0.208446      0.20474\n",
       "mse                      0.206211   0.0226852  0.179763      0.17509       0.197513      0.267399      0.192215      0.209952      0.262752      0.205565      0.168977      0.202882\n",
       "precision                0.602466   0.0858603  0.611111      0.603774      0.631579      0.447368      0.489362      0.725         0.402985      0.8           0.586207      0.727273\n",
       "r2                       0.0726078  0.118869   0.206305      0.242468      0.171201      -0.332881     0.129455      0.13116       -0.0921247    -0.043332     0.168629      0.145197\n",
       "recall                   0.819552   0.0969926  0.846154      0.969697      0.827586      0.85          0.884615      0.763158      1             0.470588      0.809524      0.774193\n",
       "rmse                     0.452806   0.0242645  0.423985      0.418437      0.444425      0.517106      0.438423      0.458205      0.512594      0.453392      0.411068      0.450424\n",
       "specificity              0.653086   0.173358   0.714286      0.637931      0.688889      0.596154      0.54717       0.8           0             0.956522      0.773585      0.816327"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_r2</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 16:01:03</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 16:01:03</td>\n",
       "<td>22.744 sec</td>\n",
       "<td>121904 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>7680.0</td>\n",
       "<td>0.3861112</td>\n",
       "<td>0.4531373</td>\n",
       "<td>0.3437906</td>\n",
       "<td>0.8507687</td>\n",
       "<td>0.7582439</td>\n",
       "<td>2.8656716</td>\n",
       "<td>0.2356771</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 16:01:06</td>\n",
       "<td>25.536 sec</td>\n",
       "<td>144212 obs/sec</td>\n",
       "<td>510.0</td>\n",
       "<td>51</td>\n",
       "<td>391680.0</td>\n",
       "<td>0.2001749</td>\n",
       "<td>0.1303558</td>\n",
       "<td>0.8236250</td>\n",
       "<td>0.9904701</td>\n",
       "<td>0.8190900</td>\n",
       "<td>2.8656716</td>\n",
       "<td>0.0494792</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2019-04-23 16:01:03  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan\n",
       "    2019-04-23 16:01:03  22.744 sec  121904 obs/sec    10        1             7680       0.386111         0.453137            0.343791       0.850769        0.758244           2.86567          0.235677\n",
       "    2019-04-23 16:01:06  25.536 sec  144212 obs/sec    510       51            391680     0.200175         0.130356            0.823625       0.99047         0.81909            2.86567          0.0494792"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>C7</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1388296</td></tr>\n",
       "<tr><td>C6</td>\n",
       "<td>0.9757255</td>\n",
       "<td>0.9757255</td>\n",
       "<td>0.1354596</td></tr>\n",
       "<tr><td>C3</td>\n",
       "<td>0.9352985</td>\n",
       "<td>0.9352985</td>\n",
       "<td>0.1298471</td></tr>\n",
       "<tr><td>C5</td>\n",
       "<td>0.9141937</td>\n",
       "<td>0.9141937</td>\n",
       "<td>0.1269171</td></tr>\n",
       "<tr><td>C4</td>\n",
       "<td>0.8967770</td>\n",
       "<td>0.8967770</td>\n",
       "<td>0.1244992</td></tr>\n",
       "<tr><td>C1</td>\n",
       "<td>0.8952525</td>\n",
       "<td>0.8952525</td>\n",
       "<td>0.1242875</td></tr>\n",
       "<tr><td>C8</td>\n",
       "<td>0.8842649</td>\n",
       "<td>0.8842649</td>\n",
       "<td>0.1227621</td></tr>\n",
       "<tr><td>C2</td>\n",
       "<td>0.7015628</td>\n",
       "<td>0.7015628</td>\n",
       "<td>0.0973977</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "C7          1                      1                    0.13883\n",
       "C6          0.975725               0.975725             0.13546\n",
       "C3          0.935299               0.935299             0.129847\n",
       "C5          0.914194               0.914194             0.126917\n",
       "C4          0.896777               0.896777             0.124499\n",
       "C1          0.895252               0.895252             0.124288\n",
       "C8          0.884265               0.884265             0.122762\n",
       "C2          0.701563               0.701563             0.0973977"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OBinomialModel.confusion_matrix of >"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_model1.confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### V . Ejemplo de deep Learning aplicado a Shuttle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████"
     ]
    }
   ],
   "source": [
    "shuttle = h2o.import_file(\"https://academic.uprm.edu/eacuna/shuttle.trn\")\n",
    "myx=['C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "shuttle['C10']=shuttle['C10'].asfactor()\n",
    "myy=\"C10\"\n",
    "dl_model = H2ODeepLearningEstimator(hidden=[10,20],epochs=200,nfolds=10)\n",
    "dl_model.train(myx, myy, training_frame=shuttle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n",
      "[0.9994022988505747]\n"
     ]
    }
   ],
   "source": [
    "y_pred=dl_model.predict(shuttle)\n",
    "print ((y_pred['predict']==shuttle['C10']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_model.model_performance(shuttle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_model_python_1556030189279_80\n",
      "\n",
      "\n",
      "ModelMetricsMultinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0006590835325818469\n",
      "RMSE: 0.025672622238132336\n",
      "LogLoss: 0.014769974246377996\n",
      "Mean Per-Class Error: 0.005736101600529597\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>7850.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0001274</td>\n",
       "<td>1 / 7,851</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 3</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0357143</td>\n",
       "<td>1 / 28</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1574.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0025349</td>\n",
       "<td>4 / 1,578</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>562.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0017762</td>\n",
       "<td>1 / 563</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 1</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 1</td></tr>\n",
       "<tr><td>7851.0</td>\n",
       "<td>6.0</td>\n",
       "<td>28.0</td>\n",
       "<td>1574.0</td>\n",
       "<td>563.0</td>\n",
       "<td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0006983</td>\n",
       "<td>7 / 10,025</td></tr></table></div>"
      ],
      "text/plain": [
       "1     2    3    4     5    6    7    Error        Rate\n",
       "----  ---  ---  ----  ---  ---  ---  -----------  ----------\n",
       "7850  1    0    0     0    0    0    0.000127372  1 / 7,851\n",
       "0     3    0    0     0    0    0    0            0 / 3\n",
       "0     0    27   0     1    0    0    0.0357143    1 / 28\n",
       "1     1    1    1574  0    1    0    0.00253485   4 / 1,578\n",
       "0     1    0    0     562  0    0    0.0017762    1 / 563\n",
       "0     0    0    0     0    1    0    0            0 / 1\n",
       "0     0    0    0     0    0    1    0            0 / 1\n",
       "7851  6    28   1574  563  2    1    0.000698254  7 / 10,025"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9993017</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9995012</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9997007</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.999302\n",
       "2    0.999501\n",
       "3    0.999701\n",
       "4    1\n",
       "5    1\n",
       "6    1\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_r2</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 10:37:20</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 10:37:20</td>\n",
       "<td> 0.687 sec</td>\n",
       "<td>181778 obs/sec</td>\n",
       "<td>2.2983448</td>\n",
       "<td>1</td>\n",
       "<td>99978.0</td>\n",
       "<td>0.0737521</td>\n",
       "<td>0.0468684</td>\n",
       "<td>0.9970396</td>\n",
       "<td>0.0052868</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 10:37:25</td>\n",
       "<td> 5.699 sec</td>\n",
       "<td>198739 obs/sec</td>\n",
       "<td>25.2878621</td>\n",
       "<td>11</td>\n",
       "<td>1100022.0</td>\n",
       "<td>0.0351314</td>\n",
       "<td>0.0184253</td>\n",
       "<td>0.9993283</td>\n",
       "<td>0.0012968</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 10:37:31</td>\n",
       "<td>11.352 sec</td>\n",
       "<td>197528 obs/sec</td>\n",
       "<td>50.5762989</td>\n",
       "<td>22</td>\n",
       "<td>2200069.0</td>\n",
       "<td>0.0296272</td>\n",
       "<td>0.0159970</td>\n",
       "<td>0.9995223</td>\n",
       "<td>0.0009975</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 10:37:36</td>\n",
       "<td>16.547 sec</td>\n",
       "<td>202347 obs/sec</td>\n",
       "<td>75.8780690</td>\n",
       "<td>33</td>\n",
       "<td>3300696.0</td>\n",
       "<td>0.0273630</td>\n",
       "<td>0.0151074</td>\n",
       "<td>0.9995925</td>\n",
       "<td>0.0007980</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 10:37:42</td>\n",
       "<td>21.850 sec</td>\n",
       "<td>203762 obs/sec</td>\n",
       "<td>101.1597011</td>\n",
       "<td>44</td>\n",
       "<td>4400447.0</td>\n",
       "<td>0.0289132</td>\n",
       "<td>0.0168791</td>\n",
       "<td>0.9995450</td>\n",
       "<td>0.0008978</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 10:37:47</td>\n",
       "<td>27.035 sec</td>\n",
       "<td>201882 obs/sec</td>\n",
       "<td>124.1600920</td>\n",
       "<td>54</td>\n",
       "<td>5400964.0</td>\n",
       "<td>0.0293062</td>\n",
       "<td>0.0188461</td>\n",
       "<td>0.9995326</td>\n",
       "<td>0.0009975</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 10:37:52</td>\n",
       "<td>32.419 sec</td>\n",
       "<td>199308 obs/sec</td>\n",
       "<td>147.1492874</td>\n",
       "<td>64</td>\n",
       "<td>6400994.0</td>\n",
       "<td>0.0274724</td>\n",
       "<td>0.0180127</td>\n",
       "<td>0.9995892</td>\n",
       "<td>0.0007980</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 10:37:58</td>\n",
       "<td>37.870 sec</td>\n",
       "<td>199778 obs/sec</td>\n",
       "<td>172.4385977</td>\n",
       "<td>75</td>\n",
       "<td>7501079.0</td>\n",
       "<td>0.0265399</td>\n",
       "<td>0.0160636</td>\n",
       "<td>0.9996166</td>\n",
       "<td>0.0006983</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 10:38:03</td>\n",
       "<td>42.943 sec</td>\n",
       "<td>199566 obs/sec</td>\n",
       "<td>195.4192644</td>\n",
       "<td>85</td>\n",
       "<td>8500738.0</td>\n",
       "<td>0.0256726</td>\n",
       "<td>0.0147700</td>\n",
       "<td>0.9996413</td>\n",
       "<td>0.0006983</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 10:38:04</td>\n",
       "<td>43.930 sec</td>\n",
       "<td>199705 obs/sec</td>\n",
       "<td>200.0080230</td>\n",
       "<td>87</td>\n",
       "<td>8700349.0</td>\n",
       "<td>0.0264604</td>\n",
       "<td>0.0160971</td>\n",
       "<td>0.9996189</td>\n",
       "<td>0.0006983</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-23 10:38:04</td>\n",
       "<td>43.953 sec</td>\n",
       "<td>199695 obs/sec</td>\n",
       "<td>200.0080230</td>\n",
       "<td>87</td>\n",
       "<td>8700349.0</td>\n",
       "<td>0.0256726</td>\n",
       "<td>0.0147700</td>\n",
       "<td>0.9996413</td>\n",
       "<td>0.0006983</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs    iterations    samples      training_rmse    training_logloss    training_r2    training_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  -----------  ---------------  ------------------  -------------  -------------------------------\n",
       "    2019-04-23 10:37:20  0.000 sec                     0         0             0            nan              nan                 nan            nan\n",
       "    2019-04-23 10:37:20  0.687 sec   181778 obs/sec    2.29834   1             99978        0.0737521        0.0468684           0.99704        0.00528678\n",
       "    2019-04-23 10:37:25  5.699 sec   198739 obs/sec    25.2879   11            1.10002e+06  0.0351314        0.0184253           0.999328       0.00129676\n",
       "    2019-04-23 10:37:31  11.352 sec  197528 obs/sec    50.5763   22            2.20007e+06  0.0296272        0.015997            0.999522       0.000997506\n",
       "    2019-04-23 10:37:36  16.547 sec  202347 obs/sec    75.8781   33            3.3007e+06   0.027363         0.0151074           0.999592       0.000798005\n",
       "    2019-04-23 10:37:42  21.850 sec  203762 obs/sec    101.16    44            4.40045e+06  0.0289132        0.0168791           0.999545       0.000897756\n",
       "    2019-04-23 10:37:47  27.035 sec  201882 obs/sec    124.16    54            5.40096e+06  0.0293062        0.0188461           0.999533       0.000997506\n",
       "    2019-04-23 10:37:52  32.419 sec  199308 obs/sec    147.149   64            6.40099e+06  0.0274724        0.0180127           0.999589       0.000798005\n",
       "    2019-04-23 10:37:58  37.870 sec  199778 obs/sec    172.439   75            7.50108e+06  0.0265399        0.0160636           0.999617       0.000698254\n",
       "    2019-04-23 10:38:03  42.943 sec  199566 obs/sec    195.419   85            8.50074e+06  0.0256726        0.01477             0.999641       0.000698254\n",
       "    2019-04-23 10:38:04  43.930 sec  199705 obs/sec    200.008   87            8.70035e+06  0.0264604        0.0160971           0.999619       0.000698254\n",
       "    2019-04-23 10:38:04  43.953 sec  199695 obs/sec    200.008   87            8.70035e+06  0.0256726        0.01477             0.999641       0.000698254"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>C2</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2115230</td></tr>\n",
       "<tr><td>C5</td>\n",
       "<td>0.6319591</td>\n",
       "<td>0.6319591</td>\n",
       "<td>0.1336739</td></tr>\n",
       "<tr><td>C7</td>\n",
       "<td>0.6110241</td>\n",
       "<td>0.6110241</td>\n",
       "<td>0.1292457</td></tr>\n",
       "<tr><td>C1</td>\n",
       "<td>0.5698003</td>\n",
       "<td>0.5698003</td>\n",
       "<td>0.1205259</td></tr>\n",
       "<tr><td>C8</td>\n",
       "<td>0.4586450</td>\n",
       "<td>0.4586450</td>\n",
       "<td>0.0970140</td></tr>\n",
       "<tr><td>C9</td>\n",
       "<td>0.4064629</td>\n",
       "<td>0.4064629</td>\n",
       "<td>0.0859762</td></tr>\n",
       "<tr><td>C4</td>\n",
       "<td>0.3580578</td>\n",
       "<td>0.3580578</td>\n",
       "<td>0.0757375</td></tr>\n",
       "<tr><td>C6</td>\n",
       "<td>0.3488592</td>\n",
       "<td>0.3488592</td>\n",
       "<td>0.0737917</td></tr>\n",
       "<tr><td>C3</td>\n",
       "<td>0.3428099</td>\n",
       "<td>0.3428099</td>\n",
       "<td>0.0725122</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "C2          1                      1                    0.211523\n",
       "C5          0.631959               0.631959             0.133674\n",
       "C7          0.611024               0.611024             0.129246\n",
       "C1          0.5698                 0.5698               0.120526\n",
       "C8          0.458645               0.458645             0.097014\n",
       "C9          0.406463               0.406463             0.0859762\n",
       "C4          0.358058               0.358058             0.0757375\n",
       "C6          0.348859               0.348859             0.0737917\n",
       "C3          0.34281                0.34281              0.0725122"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OMultinomialModel.confusion_matrix of >"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_model.confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
