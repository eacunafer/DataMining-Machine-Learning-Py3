{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining and Machine Learning\n",
    "### Clasification using Neural Networks and Deep Learning\n",
    "#### Edgar Acuna \n",
    "#### April 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 1. Neural Nets applied to the prediction of the final grade based on the first two exams: E1 and E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv(\"http://academic.uprm.edu/eacuna/eje1dis.csv\")\n",
    "df=pd.read_csv(\"c://PW-PR/eje1dis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convirtiendo en matriz la tabla de predictoras y la columna de clases\n",
    "y=df['Nota']\n",
    "X=df.iloc[:,0:2]\n",
    "#creando una columna \"pass\" numerica para representar las clases\n",
    "lb_make = LabelEncoder()\n",
    "df[\"pass\"] = lb_make.fit_transform(df[\"Nota\"])\n",
    "y2=df['pass']\n",
    "y1=y2.as_matrix()\n",
    "X1=X.as_matrix()\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X1)\n",
    "#StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "#X1= scaler.transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=5, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=99, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a neural net with one hidden layer containing 5 units\n",
    "mlp = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(5),max_iter=1000,random_state=99)\n",
    "mlp.fit(X1, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.93306393e+01, -2.19847626e-02,  4.67280387e+01,\n",
       "         -1.21251200e+01, -1.67606515e+01],\n",
       "        [ 9.31589043e+01, -3.73206703e-01,  4.15846672e+01,\n",
       "         -1.23368759e+01, -3.21037745e+00]]), array([[-7.01419931e-04],\n",
       "        [ 9.44058482e-01],\n",
       "        [ 1.10475826e-02],\n",
       "        [ 1.96857243e+00],\n",
       "        [-1.35496680e+00]])]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing  the weights\n",
    "mlp.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-7.44811572,  0.45692388,  1.39966161, -0.16317004,  0.57152039]),\n",
       " array([-51.31888278])]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing the biases\n",
    "mlp.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.00000000e+00],\n",
       "       [2.22044605e-16, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.00000000e+00],\n",
       "       [2.22044605e-16, 1.00000000e+00],\n",
       "       [3.10862447e-15, 1.00000000e+00],\n",
       "       [6.56805055e-10, 9.99999999e-01],\n",
       "       [1.19992905e-12, 1.00000000e+00],\n",
       "       [4.33475522e-09, 9.99999996e-01],\n",
       "       [2.44449664e-08, 9.99999976e-01],\n",
       "       [1.19239471e-07, 9.99999881e-01],\n",
       "       [6.26212371e-09, 9.99999994e-01],\n",
       "       [8.37275879e-04, 9.99162724e-01],\n",
       "       [1.70068306e-03, 9.98299317e-01],\n",
       "       [2.60741650e-10, 1.00000000e+00],\n",
       "       [1.20121468e-10, 1.00000000e+00],\n",
       "       [3.12620131e-01, 6.87379869e-01],\n",
       "       [8.63373567e-06, 9.99991366e-01],\n",
       "       [3.77435916e-06, 9.99996226e-01],\n",
       "       [2.69701921e-02, 9.73029808e-01],\n",
       "       [1.20471486e-04, 9.99879529e-01],\n",
       "       [1.78931027e-01, 8.21068973e-01],\n",
       "       [2.26344461e-02, 9.77365554e-01],\n",
       "       [1.69525938e-04, 9.99830474e-01],\n",
       "       [5.47287861e-07, 9.99999453e-01],\n",
       "       [9.93102033e-01, 6.89796709e-03],\n",
       "       [9.99999822e-01, 1.78404967e-07],\n",
       "       [6.06737711e-01, 3.93262289e-01],\n",
       "       [8.91513196e-01, 1.08486804e-01],\n",
       "       [9.70015752e-01, 2.99842477e-02],\n",
       "       [9.99980681e-01, 1.93191898e-05],\n",
       "       [9.68049932e-01, 3.19500677e-02],\n",
       "       [9.99963864e-01, 3.61356025e-05]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the posterior probabilities\n",
    "mlp.predict_proba(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  0]\n",
      " [ 0 24]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating the prediction matrix\n",
    "pred=mlp.predict(X1)\n",
    "print(confusion_matrix(y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este es el numero de errores= 0\n"
     ]
    }
   ],
   "source": [
    "#Calculating the number of errors\n",
    "error=(y!=pred).sum()\n",
    "print( \"Este es el numero de errores=\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f       1.00      1.00      1.00         8\n",
      "           p       1.00      1.00      1.00        24\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        32\n",
      "   macro avg       1.00      1.00      1.00        32\n",
      "weighted avg       1.00      1.00      1.00        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualizando la fromtera de decision\n",
    "from matplotlib.colors import ListedColormap\n",
    "mlp = MLPClassifier(solver=\"lbfgs\",hidden_layer_sizes=(5),max_iter=1000,random_state=99)\n",
    "mlp.fit(X1, y1) \n",
    "eje1=np.arange(start = X1[:, 0].min()-1, stop = X1[:, 0].max() + 1, step = 0.1)\n",
    "eje2=np.arange(start = X1[:, 1].min()-1, stop = X1[:, 1].max() + 1, step = 0.11)\n",
    "Y1, Y2 = np.meshgrid(eje1,eje2)\n",
    "pred2=mlp.predict(np.c_[Y1.ravel(), Y2.ravel()]).reshape(Y1.shape)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pcolormesh(Y1, Y2, pred2,cmap=plt.cm.Paired)\n",
    "# Plot also the training points#\n",
    "plt.scatter(X1[:, 0], X1[:, 1], c=y2, edgecolors='k')\n",
    "plt.xlabel('Ex1')\n",
    "plt.ylabel('Ex2')\n",
    "plt.xlim(Y1.min(), Y1.max())\n",
    "plt.ylim(Y2.min(), Y2.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 5), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=1000, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=99, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a neural net with two hidden layers containing 5 units each of them\n",
    "mlp2 = MLPClassifier(solver='lbfgs',hidden_layer_sizes=(5,5),max_iter=1000,random_state=99)\n",
    "mlp2.fit(X1, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.23049524, -0.02207448,  0.63049713, -0.64444712,  0.36133947],\n",
       "        [-0.39755451, -0.37472974, -0.81520733,  1.16250735, -0.9975528 ]]),\n",
       " array([[-0.16196165,  0.52198852,  0.36004258, -0.62957092,  0.28294691],\n",
       "        [-0.44665223,  0.084192  , -0.32181481,  0.48976489,  0.50820058],\n",
       "        [-0.43132982,  0.14973231, -0.62677501, -0.13685051, -0.6418174 ],\n",
       "        [-0.55149494, -0.49373762,  0.0625446 , -0.65435683, -0.45661181],\n",
       "        [-0.76444363,  0.58263972,  0.0809211 , -0.51503376,  0.65182766]]),\n",
       " array([[ 0.66983668],\n",
       "        [-0.0825381 ],\n",
       "        [ 0.94532955],\n",
       "        [-0.06752363],\n",
       "        [-0.30298109]])]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing  the weights\n",
    "mlp2.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.49242105,  0.45692388, -0.22506937, -0.00865967,  0.7918344 ]),\n",
       " array([ 0.06520198, -0.71764652,  0.03837523,  0.21710789,  0.4598108 ]),\n",
       " array([0.11201181])]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing  the biases\n",
    "mlp2.intercepts_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has 51 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  5]\n",
      " [ 2 22]]\n"
     ]
    }
   ],
   "source": [
    "#Calculating the prediction matrix\n",
    "pred=mlp2.predict(X1)\n",
    "print(confusion_matrix(y,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7 errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2. Nnets applied to Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      2\n",
       "1     1    85    66    29     0  26.6  0.351   31      1\n",
       "2     8   183    64     0     0  23.3  0.672   32      2\n",
       "3     1    89    66    23    94  28.1  0.167   21      1\n",
       "4     0   137    40    35   168  43.1  2.288   33      2"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#url= \"http://academic.uprm.edu/eacuna/diabetes.dat\"\n",
    "url=\"c://PW-PR/diabetes.dat\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = pd.read_table(url, names=names)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['class']\n",
    "X=data.iloc[:,0:8]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "y1=y.as_matrix()\n",
    "X1=X.as_matrix()\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X_train)\n",
    "#StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "#X_train= scaler.transform(X_train)\n",
    "#X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=20, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training a NN with one hidden layer and 20 units\n",
    "mlp=MLPClassifier(hidden_layer_sizes=(20),max_iter=500)\n",
    "mlp.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlp.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.86      0.82       130\n",
      "           2       0.64      0.52      0.57        62\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       192\n",
      "   macro avg       0.71      0.69      0.70       192\n",
      "weighted avg       0.74      0.75      0.74       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The overfitting problem in Neural Nets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 20 units\n",
    "mlp1=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(5),max_iter=1000)\n",
    "mlp1.fit(X1, y1) \n",
    "mlp1.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8046875"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 20 units\n",
    "mlp2=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(20),max_iter=1000)\n",
    "mlp2.fit(X1, y1) \n",
    "mlp2.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6510416666666666"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 50 units\n",
    "mlp3=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(50),max_iter=1000)\n",
    "mlp3.fit(X1, y1) \n",
    "mlp3.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5091145833333334"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 100 units\n",
    "mlp4=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(100),max_iter=1000)\n",
    "mlp4.fit(X1, y1) \n",
    "mlp4.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99609375"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 200 units\n",
    "mlp5=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(200),max_iter=5000)\n",
    "mlp5.fit(X1, y1) \n",
    "mlp5.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 500 units\n",
    "mlp6=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(500),max_iter=5000)\n",
    "mlp6.fit(X1, y1) \n",
    "mlp6.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8307291666666666"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 20 units, weight decay with penalty .1\n",
    "mlp6=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(20),alpha=.1,max_iter=5000)\n",
    "mlp6.fit(X1, y1) \n",
    "mlp6.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8294270833333334"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training a NN with one hidden layer and 20 units, weight decay with penalty 5\n",
    "mlp6=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(20),alpha=5,max_iter=5000)\n",
    "mlp6.fit(X1, y1) \n",
    "mlp6.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8515625"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training a NN with two hidden layer and 20 units in each of them\n",
    "mlp22=MLPClassifier(solver='lbfgs',hidden_layer_sizes=(20,20),max_iter=5000)\n",
    "mlp22.fit(X1, y1) \n",
    "mlp22.score(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy estimated by CV is: 0.7383629528366371\n"
     ]
    }
   ],
   "source": [
    "#Estimating the accuracy using cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(mlp2, X1, y1, cv=10)\n",
    "print ('The accuracy estimated by CV is:', scores.mean())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3. Nnet  applied to Landsat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargando el conjunto de datos Landsat\n",
    "#url='http://academic.uprm.edu/eacuna/landsat.txt'\n",
    "url='c://PW-PR/landsat.data'\n",
    "data = pd.read_table(url, header=None,delim_whitespace=True)\n",
    "y=data.iloc[:,36]\n",
    "X=data.iloc[:,0:36]\n",
    "#y1=y.as_matrix()\n",
    "#X1=X.as_matrix()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "X_train= scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(50, 50, 50), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimacion de la precision con k=3 vecinos  por el metodo  \"holdout \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "mlp=MLPClassifier(hidden_layer_sizes=(50,50,50),max_iter=500)\n",
    "mlp.fit(X_train, y_train) \n",
    "mlp.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[401   0   3   0   2   0]\n",
      " [  0 160   0   1   4   1]\n",
      " [  2   0 327   4   0  24]\n",
      " [  2   0  74  15   3  45]\n",
      " [ 16   1   0   1 135  28]\n",
      " [  0   0  47  12   4 297]]\n"
     ]
    }
   ],
   "source": [
    "pred=mlp.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.99      0.97       406\n",
      "           2       0.99      0.96      0.98       166\n",
      "           3       0.73      0.92      0.81       357\n",
      "           4       0.45      0.11      0.17       139\n",
      "           5       0.91      0.75      0.82       181\n",
      "           7       0.75      0.82      0.79       360\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1609\n",
      "   macro avg       0.80      0.76      0.76      1609\n",
      "weighted avg       0.81      0.83      0.81      1609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Ejemplo de Deep Learning aplicado a Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54323. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>57 mins 21 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/La_Paz</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.1.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>2 months and 22 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_edgar2017_wt7vhk</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>1.584 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54323</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.5.5 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  --------------------------------\n",
       "H2O cluster uptime:         57 mins 21 secs\n",
       "H2O cluster timezone:       America/La_Paz\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.1.2\n",
       "H2O cluster version age:    2 months and 22 days\n",
       "H2O cluster name:           H2O_from_python_edgar2017_wt7vhk\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    1.584 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54323\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.5.5 final\n",
       "--------------------------  --------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init(ip=\"localhost\", port=54323)\n",
    "from h2o.estimators.deeplearning import H2OAutoEncoderEstimator, H2ODeepLearningEstimator\n",
    "#h2o.connect()\n",
    "#h2o.no_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "diabetes = h2o.import_file(\"https://academic.uprm.edu/eacuna/diabetes.dat\")\n",
    "myx=['C1','C2','C3','C4','C5','C6','C7','C8']\n",
    "diabetes['C9']=diabetes['C9'].asfactor()\n",
    "myy=\"C9\"\n",
    "dl_model = H2ODeepLearningEstimator(hidden=[10,10],epochs=200)\n",
    "dl_model.train(myx, myy, training_frame=diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n",
      "[0.78515625]\n"
     ]
    }
   ],
   "source": [
    "y_pred=dl_model.predict(diabetes)\n",
    "print( (y_pred['predict']==diabetes['C9']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.13122022031048505\n",
      "RMSE: 0.36224331644694985\n",
      "LogLoss: 0.40614145258222994\n",
      "Mean Per-Class Error: 0.1937014925373135\n",
      "AUC: 0.8902276119402985\n",
      "pr_auc: 0.8070006070550624\n",
      "Gini: 0.7804552238805971\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.3582035925759589: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>366.0</td>\n",
       "<td>134.0</td>\n",
       "<td>0.268</td>\n",
       "<td> (134.0/500.0)</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>32.0</td>\n",
       "<td>236.0</td>\n",
       "<td>0.1194</td>\n",
       "<td> (32.0/268.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>398.0</td>\n",
       "<td>370.0</td>\n",
       "<td>0.2161</td>\n",
       "<td> (166.0/768.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       1    2    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "1      366  134  0.268    (134.0/500.0)\n",
       "2      32   236  0.1194   (32.0/268.0)\n",
       "Total  398  370  0.2161   (166.0/768.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3582036</td>\n",
       "<td>0.7398119</td>\n",
       "<td>227.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2170705</td>\n",
       "<td>0.8316961</td>\n",
       "<td>278.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7011819</td>\n",
       "<td>0.7673745</td>\n",
       "<td>111.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7011819</td>\n",
       "<td>0.8151042</td>\n",
       "<td>111.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9984030</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0339671</td>\n",
       "<td>1.0</td>\n",
       "<td>373.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9984030</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5515601</td>\n",
       "<td>0.5898563</td>\n",
       "<td>157.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4576812</td>\n",
       "<td>0.796</td>\n",
       "<td>192.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3582036</td>\n",
       "<td>0.8062985</td>\n",
       "<td>227.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.358204     0.739812  227\n",
       "max f2                       0.21707      0.831696  278\n",
       "max f0point5                 0.701182     0.767375  111\n",
       "max accuracy                 0.701182     0.815104  111\n",
       "max precision                0.998403     1         0\n",
       "max recall                   0.0339671    1         373\n",
       "max specificity              0.998403     1         0\n",
       "max absolute_mcc             0.55156      0.589856  157\n",
       "max min_per_class_accuracy   0.457681     0.796     192\n",
       "max mean_per_class_accuracy  0.358204     0.806299  227"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 34.90 %, avg score: 40.65 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0104167</td>\n",
       "<td>0.9928349</td>\n",
       "<td>2.5074627</td>\n",
       "<td>2.5074627</td>\n",
       "<td>0.875</td>\n",
       "<td>0.9953535</td>\n",
       "<td>0.875</td>\n",
       "<td>0.9953535</td>\n",
       "<td>0.0261194</td>\n",
       "<td>0.0261194</td>\n",
       "<td>150.7462687</td>\n",
       "<td>150.7462687</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.9830131</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.6865672</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9872451</td>\n",
       "<td>0.9375</td>\n",
       "<td>0.9912993</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0559701</td>\n",
       "<td>186.5671642</td>\n",
       "<td>168.6567164</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03125</td>\n",
       "<td>0.9782680</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.7462687</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9801499</td>\n",
       "<td>0.9583333</td>\n",
       "<td>0.9875829</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0858209</td>\n",
       "<td>186.5671642</td>\n",
       "<td>174.6268657</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0403646</td>\n",
       "<td>0.9680885</td>\n",
       "<td>2.4562900</td>\n",
       "<td>2.6807896</td>\n",
       "<td>0.8571429</td>\n",
       "<td>0.9736503</td>\n",
       "<td>0.9354839</td>\n",
       "<td>0.9844368</td>\n",
       "<td>0.0223881</td>\n",
       "<td>0.1082090</td>\n",
       "<td>145.6289979</td>\n",
       "<td>168.0789600</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0507812</td>\n",
       "<td>0.9567288</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.7187141</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9626310</td>\n",
       "<td>0.9487179</td>\n",
       "<td>0.9799638</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.1380597</td>\n",
       "<td>186.5671642</td>\n",
       "<td>171.8714122</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1002604</td>\n",
       "<td>0.9182659</td>\n",
       "<td>2.6394344</td>\n",
       "<td>2.6795891</td>\n",
       "<td>0.9210526</td>\n",
       "<td>0.9384225</td>\n",
       "<td>0.9350649</td>\n",
       "<td>0.9594629</td>\n",
       "<td>0.1305970</td>\n",
       "<td>0.2686567</td>\n",
       "<td>163.9434407</td>\n",
       "<td>167.9589068</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1510417</td>\n",
       "<td>0.8661409</td>\n",
       "<td>2.4247991</td>\n",
       "<td>2.5939269</td>\n",
       "<td>0.8461538</td>\n",
       "<td>0.8895931</td>\n",
       "<td>0.9051724</td>\n",
       "<td>0.9359722</td>\n",
       "<td>0.1231343</td>\n",
       "<td>0.3917910</td>\n",
       "<td>142.4799082</td>\n",
       "<td>159.3926917</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2005208</td>\n",
       "<td>0.7981723</td>\n",
       "<td>2.1115475</td>\n",
       "<td>2.4748982</td>\n",
       "<td>0.7368421</td>\n",
       "<td>0.8359080</td>\n",
       "<td>0.8636364</td>\n",
       "<td>0.9112810</td>\n",
       "<td>0.1044776</td>\n",
       "<td>0.4962687</td>\n",
       "<td>111.1547526</td>\n",
       "<td>147.4898236</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3007812</td>\n",
       "<td>0.6303157</td>\n",
       "<td>1.6375267</td>\n",
       "<td>2.1957744</td>\n",
       "<td>0.5714286</td>\n",
       "<td>0.7074121</td>\n",
       "<td>0.7662338</td>\n",
       "<td>0.8433247</td>\n",
       "<td>0.1641791</td>\n",
       "<td>0.6604478</td>\n",
       "<td>63.7526652</td>\n",
       "<td>119.5774375</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3997396</td>\n",
       "<td>0.4732731</td>\n",
       "<td>1.2443048</td>\n",
       "<td>1.9602314</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.5502835</td>\n",
       "<td>0.6840391</td>\n",
       "<td>0.7707803</td>\n",
       "<td>0.1231343</td>\n",
       "<td>0.7835821</td>\n",
       "<td>24.4304792</td>\n",
       "<td>96.0231416</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.3240734</td>\n",
       "<td>1.0420624</td>\n",
       "<td>1.7761194</td>\n",
       "<td>0.3636364</td>\n",
       "<td>0.4037269</td>\n",
       "<td>0.6197917</td>\n",
       "<td>0.6971784</td>\n",
       "<td>0.1044776</td>\n",
       "<td>0.8880597</td>\n",
       "<td>4.2062415</td>\n",
       "<td>77.6119403</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6002604</td>\n",
       "<td>0.2075809</td>\n",
       "<td>0.5954642</td>\n",
       "<td>1.5789167</td>\n",
       "<td>0.2077922</td>\n",
       "<td>0.2644805</td>\n",
       "<td>0.5509761</td>\n",
       "<td>0.6249057</td>\n",
       "<td>0.0597015</td>\n",
       "<td>0.9477612</td>\n",
       "<td>-40.4535763</td>\n",
       "<td>57.8916696</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6992188</td>\n",
       "<td>0.1217155</td>\n",
       "<td>0.3770621</td>\n",
       "<td>1.4088218</td>\n",
       "<td>0.1315789</td>\n",
       "<td>0.1653863</td>\n",
       "<td>0.4916201</td>\n",
       "<td>0.5598713</td>\n",
       "<td>0.0373134</td>\n",
       "<td>0.9850746</td>\n",
       "<td>-62.2937942</td>\n",
       "<td>40.8821813</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7994792</td>\n",
       "<td>0.0645671</td>\n",
       "<td>0.0744330</td>\n",
       "<td>1.2414799</td>\n",
       "<td>0.0259740</td>\n",
       "<td>0.0924239</td>\n",
       "<td>0.4332248</td>\n",
       "<td>0.5012500</td>\n",
       "<td>0.0074627</td>\n",
       "<td>0.9925373</td>\n",
       "<td>-92.5566970</td>\n",
       "<td>24.1479897</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8997396</td>\n",
       "<td>0.0266831</td>\n",
       "<td>0.0744330</td>\n",
       "<td>1.1114327</td>\n",
       "<td>0.0259740</td>\n",
       "<td>0.0443660</td>\n",
       "<td>0.3878437</td>\n",
       "<td>0.4503382</td>\n",
       "<td>0.0074627</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.5566970</td>\n",
       "<td>11.1432706</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0021018</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0132969</td>\n",
       "<td>0.3489583</td>\n",
       "<td>0.4065203</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0104167                   0.992835           2.50746   2.50746            0.875            0.995354   0.875                       0.995354            0.0261194       0.0261194                  150.746   150.746\n",
       "    2        0.0208333                   0.983013           2.86567   2.68657            1                0.987245   0.9375                      0.991299            0.0298507       0.0559701                  186.567   168.657\n",
       "    3        0.03125                     0.978268           2.86567   2.74627            1                0.98015    0.958333                    0.987583            0.0298507       0.0858209                  186.567   174.627\n",
       "    4        0.0403646                   0.968089           2.45629   2.68079            0.857143         0.97365    0.935484                    0.984437            0.0223881       0.108209                   145.629   168.079\n",
       "    5        0.0507812                   0.956729           2.86567   2.71871            1                0.962631   0.948718                    0.979964            0.0298507       0.13806                    186.567   171.871\n",
       "    6        0.10026                     0.918266           2.63943   2.67959            0.921053         0.938422   0.935065                    0.959463            0.130597        0.268657                   163.943   167.959\n",
       "    7        0.151042                    0.866141           2.4248    2.59393            0.846154         0.889593   0.905172                    0.935972            0.123134        0.391791                   142.48    159.393\n",
       "    8        0.200521                    0.798172           2.11155   2.4749             0.736842         0.835908   0.863636                    0.911281            0.104478        0.496269                   111.155   147.49\n",
       "    9        0.300781                    0.630316           1.63753   2.19577            0.571429         0.707412   0.766234                    0.843325            0.164179        0.660448                   63.7527   119.577\n",
       "    10       0.39974                     0.473273           1.2443    1.96023            0.434211         0.550283   0.684039                    0.77078             0.123134        0.783582                   24.4305   96.0231\n",
       "    11       0.5                         0.324073           1.04206   1.77612            0.363636         0.403727   0.619792                    0.697178            0.104478        0.88806                    4.20624   77.6119\n",
       "    12       0.60026                     0.207581           0.595464  1.57892            0.207792         0.264481   0.550976                    0.624906            0.0597015       0.947761                   -40.4536  57.8917\n",
       "    13       0.699219                    0.121716           0.377062  1.40882            0.131579         0.165386   0.49162                     0.559871            0.0373134       0.985075                   -62.2938  40.8822\n",
       "    14       0.799479                    0.0645671          0.074433  1.24148            0.025974         0.0924239  0.433225                    0.50125             0.00746269      0.992537                   -92.5567  24.148\n",
       "    15       0.89974                     0.0266831          0.074433  1.11143            0.025974         0.044366   0.387844                    0.450338            0.00746269      1                          -92.5567  11.1433\n",
       "    16       1                           0.00210184         0         1                  0                0.0132969  0.348958                    0.40652             0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_model.model_performance(diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "dl_model1 = H2ODeepLearningEstimator(hidden=[20,20,20],epochs=500,nfolds=10)\n",
    "dl_model1.train(myx, myy, training_frame=diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_model_python_1554922755540_94\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.03594044168946623\n",
      "RMSE: 0.18957964471289165\n",
      "LogLoss: 0.128907704593509\n",
      "Mean Per-Class Error: 0.04525373134328359\n",
      "AUC: 0.9903582089552239\n",
      "pr_auc: 0.7598400536828939\n",
      "Gini: 0.9807164179104477\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.28613595390672064: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>486.0</td>\n",
       "<td>14.0</td>\n",
       "<td>0.028</td>\n",
       "<td> (14.0/500.0)</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>18.0</td>\n",
       "<td>250.0</td>\n",
       "<td>0.0672</td>\n",
       "<td> (18.0/268.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>504.0</td>\n",
       "<td>264.0</td>\n",
       "<td>0.0417</td>\n",
       "<td> (32.0/768.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       1    2    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "1      486  14   0.028    (14.0/500.0)\n",
       "2      18   250  0.0672   (18.0/268.0)\n",
       "Total  504  264  0.0417   (32.0/768.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2861360</td>\n",
       "<td>0.9398496</td>\n",
       "<td>162.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1248131</td>\n",
       "<td>0.9485294</td>\n",
       "<td>186.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6029379</td>\n",
       "<td>0.9556452</td>\n",
       "<td>141.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3122782</td>\n",
       "<td>0.9583333</td>\n",
       "<td>160.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0030041</td>\n",
       "<td>1.0</td>\n",
       "<td>315.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9999999</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2861360</td>\n",
       "<td>0.9080399</td>\n",
       "<td>162.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1596221</td>\n",
       "<td>0.954</td>\n",
       "<td>177.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1741578</td>\n",
       "<td>0.9547463</td>\n",
       "<td>174.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.286136     0.93985   162\n",
       "max f2                       0.124813     0.948529  186\n",
       "max f0point5                 0.602938     0.955645  141\n",
       "max accuracy                 0.312278     0.958333  160\n",
       "max precision                1            1         0\n",
       "max recall                   0.00300414   1         315\n",
       "max specificity              1            1         0\n",
       "max absolute_mcc             0.286136     0.90804   162\n",
       "max min_per_class_accuracy   0.159622     0.954     177\n",
       "max mean_per_class_accuracy  0.174158     0.954746  174"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 34.90 %, avg score: 32.75 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0104167</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0298507</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0208333</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0597015</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03125</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0895522</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0403646</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0261194</td>\n",
       "<td>0.1156716</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0507812</td>\n",
       "<td>1.0000000</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0000000</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.1455224</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1002604</td>\n",
       "<td>0.9999624</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999927</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9999964</td>\n",
       "<td>0.1417910</td>\n",
       "<td>0.2873134</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1510417</td>\n",
       "<td>0.9994265</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9996950</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9998951</td>\n",
       "<td>0.1455224</td>\n",
       "<td>0.4328358</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2005208</td>\n",
       "<td>0.9902718</td>\n",
       "<td>2.7902592</td>\n",
       "<td>2.8470634</td>\n",
       "<td>0.9736842</td>\n",
       "<td>0.9958814</td>\n",
       "<td>0.9935065</td>\n",
       "<td>0.9989047</td>\n",
       "<td>0.1380597</td>\n",
       "<td>0.5708955</td>\n",
       "<td>179.0259230</td>\n",
       "<td>184.7063384</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3007812</td>\n",
       "<td>0.8088721</td>\n",
       "<td>2.7540221</td>\n",
       "<td>2.8160496</td>\n",
       "<td>0.9610390</td>\n",
       "<td>0.9418392</td>\n",
       "<td>0.9826840</td>\n",
       "<td>0.9798828</td>\n",
       "<td>0.2761194</td>\n",
       "<td>0.8470149</td>\n",
       "<td>175.4022097</td>\n",
       "<td>181.6049622</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3997396</td>\n",
       "<td>0.0515227</td>\n",
       "<td>1.2443048</td>\n",
       "<td>2.4269532</td>\n",
       "<td>0.4342105</td>\n",
       "<td>0.3053485</td>\n",
       "<td>0.8469055</td>\n",
       "<td>0.8128971</td>\n",
       "<td>0.1231343</td>\n",
       "<td>0.9701493</td>\n",
       "<td>24.4304792</td>\n",
       "<td>142.6953182</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0079198</td>\n",
       "<td>0.2232991</td>\n",
       "<td>1.9850746</td>\n",
       "<td>0.0779221</td>\n",
       "<td>0.0203600</td>\n",
       "<td>0.6927083</td>\n",
       "<td>0.6539769</td>\n",
       "<td>0.0223881</td>\n",
       "<td>0.9925373</td>\n",
       "<td>-77.6700911</td>\n",
       "<td>98.5074627</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6002604</td>\n",
       "<td>0.0014054</td>\n",
       "<td>0.0744330</td>\n",
       "<td>1.6659436</td>\n",
       "<td>0.0259740</td>\n",
       "<td>0.0040176</td>\n",
       "<td>0.5813449</td>\n",
       "<td>0.5454154</td>\n",
       "<td>0.0074627</td>\n",
       "<td>1.0</td>\n",
       "<td>-92.5566970</td>\n",
       "<td>66.5943601</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6992188</td>\n",
       "<td>0.0002016</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4301676</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0006545</td>\n",
       "<td>0.4990689</td>\n",
       "<td>0.4683170</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>43.0167598</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7994792</td>\n",
       "<td>0.0000118</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2508143</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000795</td>\n",
       "<td>0.4364821</td>\n",
       "<td>0.4095967</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0814332</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8997396</td>\n",
       "<td>0.0000004</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1114327</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000042</td>\n",
       "<td>0.3878437</td>\n",
       "<td>0.3639547</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1432706</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000000</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0000001</td>\n",
       "<td>0.3489583</td>\n",
       "<td>0.3274644</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score        cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  -----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0104167                   1                  2.86567   2.86567            1                1            1                           1                   0.0298507       0.0298507                  186.567   186.567\n",
       "    2        0.0208333                   1                  2.86567   2.86567            1                1            1                           1                   0.0298507       0.0597015                  186.567   186.567\n",
       "    3        0.03125                     1                  2.86567   2.86567            1                1            1                           1                   0.0298507       0.0895522                  186.567   186.567\n",
       "    4        0.0403646                   1                  2.86567   2.86567            1                1            1                           1                   0.0261194       0.115672                   186.567   186.567\n",
       "    5        0.0507812                   1                  2.86567   2.86567            1                1            1                           1                   0.0298507       0.145522                   186.567   186.567\n",
       "    6        0.10026                     0.999962           2.86567   2.86567            1                0.999993     1                           0.999996            0.141791        0.287313                   186.567   186.567\n",
       "    7        0.151042                    0.999426           2.86567   2.86567            1                0.999695     1                           0.999895            0.145522        0.432836                   186.567   186.567\n",
       "    8        0.200521                    0.990272           2.79026   2.84706            0.973684         0.995881     0.993506                    0.998905            0.13806         0.570896                   179.026   184.706\n",
       "    9        0.300781                    0.808872           2.75402   2.81605            0.961039         0.941839     0.982684                    0.979883            0.276119        0.847015                   175.402   181.605\n",
       "    10       0.39974                     0.0515227          1.2443    2.42695            0.434211         0.305348     0.846906                    0.812897            0.123134        0.970149                   24.4305   142.695\n",
       "    11       0.5                         0.0079198          0.223299  1.98507            0.0779221        0.02036      0.692708                    0.653977            0.0223881       0.992537                   -77.6701  98.5075\n",
       "    12       0.60026                     0.00140539         0.074433  1.66594            0.025974         0.00401758   0.581345                    0.545415            0.00746269      1                          -92.5567  66.5944\n",
       "    13       0.699219                    0.00020159         0         1.43017            0                0.000654487  0.499069                    0.468317            0               1                          -100      43.0168\n",
       "    14       0.799479                    1.18037e-05        0         1.25081            0                7.94921e-05  0.436482                    0.409597            0               1                          -100      25.0814\n",
       "    15       0.89974                     4.22849e-07        0         1.11143            0                4.15857e-06  0.387844                    0.363955            0               1                          -100      11.1433\n",
       "    16       1                           1.47526e-20        0         1                  0                6.85795e-08  0.348958                    0.327464            0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: deeplearning\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.19124876654657794\n",
      "RMSE: 0.43731998187434556\n",
      "LogLoss: 0.577152524513946\n",
      "Mean Per-Class Error: 0.29008955223880606\n",
      "AUC: 0.7796007462686567\n",
      "pr_auc: 0.6691693947314856\n",
      "Gini: 0.5592014925373134\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.30434766167425115: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>314.0</td>\n",
       "<td>186.0</td>\n",
       "<td>0.372</td>\n",
       "<td> (186.0/500.0)</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>58.0</td>\n",
       "<td>210.0</td>\n",
       "<td>0.2164</td>\n",
       "<td> (58.0/268.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>372.0</td>\n",
       "<td>396.0</td>\n",
       "<td>0.3177</td>\n",
       "<td> (244.0/768.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       1    2    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "1      314  186  0.372    (186.0/500.0)\n",
       "2      58   210  0.2164   (58.0/268.0)\n",
       "Total  372  396  0.3177   (244.0/768.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3043477</td>\n",
       "<td>0.6325301</td>\n",
       "<td>238.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1286200</td>\n",
       "<td>0.7569231</td>\n",
       "<td>317.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.7133440</td>\n",
       "<td>0.6442308</td>\n",
       "<td>102.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.7133440</td>\n",
       "<td>0.7486979</td>\n",
       "<td>102.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9913254</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0044174</td>\n",
       "<td>1.0</td>\n",
       "<td>398.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9913254</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6378824</td>\n",
       "<td>0.4317117</td>\n",
       "<td>128.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4424855</td>\n",
       "<td>0.7052239</td>\n",
       "<td>197.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.6378824</td>\n",
       "<td>0.7099104</td>\n",
       "<td>128.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.304348     0.63253   238\n",
       "max f2                       0.12862      0.756923  317\n",
       "max f0point5                 0.713344     0.644231  102\n",
       "max accuracy                 0.713344     0.748698  102\n",
       "max precision                0.991325     1         0\n",
       "max recall                   0.00441742   1         398\n",
       "max specificity              0.991325     1         0\n",
       "max absolute_mcc             0.637882     0.431712  128\n",
       "max min_per_class_accuracy   0.442486     0.705224  197\n",
       "max mean_per_class_accuracy  0.637882     0.70991   128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 34.90 %, avg score: 40.95 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0104167</td>\n",
       "<td>0.9862403</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.8656716</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9884733</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9884733</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0298507</td>\n",
       "<td>186.5671642</td>\n",
       "<td>186.5671642</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.9758827</td>\n",
       "<td>2.1492537</td>\n",
       "<td>2.5074627</td>\n",
       "<td>0.75</td>\n",
       "<td>0.9816666</td>\n",
       "<td>0.875</td>\n",
       "<td>0.9850700</td>\n",
       "<td>0.0223881</td>\n",
       "<td>0.0522388</td>\n",
       "<td>114.9253731</td>\n",
       "<td>150.7462687</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.03125</td>\n",
       "<td>0.9665555</td>\n",
       "<td>2.8656716</td>\n",
       "<td>2.6268657</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9724060</td>\n",
       "<td>0.9166667</td>\n",
       "<td>0.9808486</td>\n",
       "<td>0.0298507</td>\n",
       "<td>0.0820896</td>\n",
       "<td>186.5671642</td>\n",
       "<td>162.6865672</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0403646</td>\n",
       "<td>0.9582323</td>\n",
       "<td>2.4562900</td>\n",
       "<td>2.5883486</td>\n",
       "<td>0.8571429</td>\n",
       "<td>0.9631907</td>\n",
       "<td>0.9032258</td>\n",
       "<td>0.9768614</td>\n",
       "<td>0.0223881</td>\n",
       "<td>0.1044776</td>\n",
       "<td>145.6289979</td>\n",
       "<td>158.8348580</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0507812</td>\n",
       "<td>0.9437656</td>\n",
       "<td>1.7910448</td>\n",
       "<td>2.4247991</td>\n",
       "<td>0.625</td>\n",
       "<td>0.9518205</td>\n",
       "<td>0.8461538</td>\n",
       "<td>0.9717248</td>\n",
       "<td>0.0186567</td>\n",
       "<td>0.1231343</td>\n",
       "<td>79.1044776</td>\n",
       "<td>142.4799082</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1002604</td>\n",
       "<td>0.8805322</td>\n",
       "<td>2.3377848</td>\n",
       "<td>2.3818569</td>\n",
       "<td>0.8157895</td>\n",
       "<td>0.9138194</td>\n",
       "<td>0.8311688</td>\n",
       "<td>0.9431481</td>\n",
       "<td>0.1156716</td>\n",
       "<td>0.2388060</td>\n",
       "<td>133.7784760</td>\n",
       "<td>138.1856949</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1510417</td>\n",
       "<td>0.8335051</td>\n",
       "<td>1.7634902</td>\n",
       "<td>2.1739578</td>\n",
       "<td>0.6153846</td>\n",
       "<td>0.8550619</td>\n",
       "<td>0.7586207</td>\n",
       "<td>0.9135329</td>\n",
       "<td>0.0895522</td>\n",
       "<td>0.3283582</td>\n",
       "<td>76.3490241</td>\n",
       "<td>117.3957797</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2005208</td>\n",
       "<td>0.7772838</td>\n",
       "<td>1.5082482</td>\n",
       "<td>2.0096918</td>\n",
       "<td>0.5263158</td>\n",
       "<td>0.8060476</td>\n",
       "<td>0.7012987</td>\n",
       "<td>0.8870106</td>\n",
       "<td>0.0746269</td>\n",
       "<td>0.4029851</td>\n",
       "<td>50.8248233</td>\n",
       "<td>100.9691801</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3007812</td>\n",
       "<td>0.6509575</td>\n",
       "<td>1.6003101</td>\n",
       "<td>1.8732312</td>\n",
       "<td>0.5584416</td>\n",
       "<td>0.7131366</td>\n",
       "<td>0.6536797</td>\n",
       "<td>0.8290526</td>\n",
       "<td>0.1604478</td>\n",
       "<td>0.5634328</td>\n",
       "<td>60.0310138</td>\n",
       "<td>87.3231246</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3997396</td>\n",
       "<td>0.4935309</td>\n",
       "<td>0.9049489</td>\n",
       "<td>1.6335262</td>\n",
       "<td>0.3157895</td>\n",
       "<td>0.5722656</td>\n",
       "<td>0.5700326</td>\n",
       "<td>0.7654832</td>\n",
       "<td>0.0895522</td>\n",
       "<td>0.6529851</td>\n",
       "<td>-9.5051060</td>\n",
       "<td>63.3526180</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.3145011</td>\n",
       "<td>1.1164954</td>\n",
       "<td>1.5298507</td>\n",
       "<td>0.3896104</td>\n",
       "<td>0.4024577</td>\n",
       "<td>0.5338542</td>\n",
       "<td>0.6926890</td>\n",
       "<td>0.1119403</td>\n",
       "<td>0.7649254</td>\n",
       "<td>11.6495445</td>\n",
       "<td>52.9850746</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6002604</td>\n",
       "<td>0.2207492</td>\n",
       "<td>0.8187633</td>\n",
       "<td>1.4110791</td>\n",
       "<td>0.2857143</td>\n",
       "<td>0.2674326</td>\n",
       "<td>0.4924078</td>\n",
       "<td>0.6216592</td>\n",
       "<td>0.0820896</td>\n",
       "<td>0.8470149</td>\n",
       "<td>-18.1236674</td>\n",
       "<td>41.1079095</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6992188</td>\n",
       "<td>0.1358786</td>\n",
       "<td>0.5655931</td>\n",
       "<td>1.2914200</td>\n",
       "<td>0.1973684</td>\n",
       "<td>0.1796178</td>\n",
       "<td>0.4506518</td>\n",
       "<td>0.5590984</td>\n",
       "<td>0.0559701</td>\n",
       "<td>0.9029851</td>\n",
       "<td>-43.4406913</td>\n",
       "<td>29.1419995</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7994792</td>\n",
       "<td>0.0861436</td>\n",
       "<td>0.4465982</td>\n",
       "<td>1.1854733</td>\n",
       "<td>0.1558442</td>\n",
       "<td>0.1098213</td>\n",
       "<td>0.4136808</td>\n",
       "<td>0.5027558</td>\n",
       "<td>0.0447761</td>\n",
       "<td>0.9477612</td>\n",
       "<td>-55.3401822</td>\n",
       "<td>18.5473285</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8997396</td>\n",
       "<td>0.0347455</td>\n",
       "<td>0.3721651</td>\n",
       "<td>1.0948442</td>\n",
       "<td>0.1298701</td>\n",
       "<td>0.0584169</td>\n",
       "<td>0.3820550</td>\n",
       "<td>0.4532419</td>\n",
       "<td>0.0373134</td>\n",
       "<td>0.9850746</td>\n",
       "<td>-62.7834852</td>\n",
       "<td>9.4844158</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0003145</td>\n",
       "<td>0.1488661</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0519481</td>\n",
       "<td>0.0169702</td>\n",
       "<td>0.3489583</td>\n",
       "<td>0.4095012</td>\n",
       "<td>0.0149254</td>\n",
       "<td>1.0</td>\n",
       "<td>-85.1133941</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0104167                   0.98624            2.86567   2.86567            1                0.988473   1                           0.988473            0.0298507       0.0298507                  186.567   186.567\n",
       "    2        0.0208333                   0.975883           2.14925   2.50746            0.75             0.981667   0.875                       0.98507             0.0223881       0.0522388                  114.925   150.746\n",
       "    3        0.03125                     0.966556           2.86567   2.62687            1                0.972406   0.916667                    0.980849            0.0298507       0.0820896                  186.567   162.687\n",
       "    4        0.0403646                   0.958232           2.45629   2.58835            0.857143         0.963191   0.903226                    0.976861            0.0223881       0.104478                   145.629   158.835\n",
       "    5        0.0507812                   0.943766           1.79104   2.4248             0.625            0.951821   0.846154                    0.971725            0.0186567       0.123134                   79.1045   142.48\n",
       "    6        0.10026                     0.880532           2.33778   2.38186            0.815789         0.913819   0.831169                    0.943148            0.115672        0.238806                   133.778   138.186\n",
       "    7        0.151042                    0.833505           1.76349   2.17396            0.615385         0.855062   0.758621                    0.913533            0.0895522       0.328358                   76.349    117.396\n",
       "    8        0.200521                    0.777284           1.50825   2.00969            0.526316         0.806048   0.701299                    0.887011            0.0746269       0.402985                   50.8248   100.969\n",
       "    9        0.300781                    0.650958           1.60031   1.87323            0.558442         0.713137   0.65368                     0.829053            0.160448        0.563433                   60.031    87.3231\n",
       "    10       0.39974                     0.493531           0.904949  1.63353            0.315789         0.572266   0.570033                    0.765483            0.0895522       0.652985                   -9.50511  63.3526\n",
       "    11       0.5                         0.314501           1.1165    1.52985            0.38961          0.402458   0.533854                    0.692689            0.11194         0.764925                   11.6495   52.9851\n",
       "    12       0.60026                     0.220749           0.818763  1.41108            0.285714         0.267433   0.492408                    0.621659            0.0820896       0.847015                   -18.1237  41.1079\n",
       "    13       0.699219                    0.135879           0.565593  1.29142            0.197368         0.179618   0.450652                    0.559098            0.0559701       0.902985                   -43.4407  29.142\n",
       "    14       0.799479                    0.0861436          0.446598  1.18547            0.155844         0.109821   0.413681                    0.502756            0.0447761       0.947761                   -55.3402  18.5473\n",
       "    15       0.89974                     0.0347455          0.372165  1.09484            0.12987          0.0584169  0.382055                    0.453242            0.0373134       0.985075                   -62.7835  9.48442\n",
       "    16       1                           0.000314488        0.148866  1                  0.0519481        0.0169702  0.348958                    0.409501            0.0149254       1                          -85.1134  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td>\n",
       "<td><b>cv_6_valid</b></td>\n",
       "<td><b>cv_7_valid</b></td>\n",
       "<td><b>cv_8_valid</b></td>\n",
       "<td><b>cv_9_valid</b></td>\n",
       "<td><b>cv_10_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.7560378</td>\n",
       "<td>0.0348619</td>\n",
       "<td>0.7611940</td>\n",
       "<td>0.7205882</td>\n",
       "<td>0.8205128</td>\n",
       "<td>0.8352941</td>\n",
       "<td>0.6790124</td>\n",
       "<td>0.7763158</td>\n",
       "<td>0.75</td>\n",
       "<td>0.7558140</td>\n",
       "<td>0.7804878</td>\n",
       "<td>0.6811594</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.8037068</td>\n",
       "<td>0.0259543</td>\n",
       "<td>0.8009524</td>\n",
       "<td>0.7831603</td>\n",
       "<td>0.7605519</td>\n",
       "<td>0.8848485</td>\n",
       "<td>0.7708074</td>\n",
       "<td>0.8590557</td>\n",
       "<td>0.7915385</td>\n",
       "<td>0.8</td>\n",
       "<td>0.7874763</td>\n",
       "<td>0.7986767</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.2439621</td>\n",
       "<td>0.0348619</td>\n",
       "<td>0.2388060</td>\n",
       "<td>0.2794118</td>\n",
       "<td>0.1794872</td>\n",
       "<td>0.1647059</td>\n",
       "<td>0.3209876</td>\n",
       "<td>0.2236842</td>\n",
       "<td>0.25</td>\n",
       "<td>0.2441860</td>\n",
       "<td>0.2195122</td>\n",
       "<td>0.3188406</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>18.6</td>\n",
       "<td>2.4939928</td>\n",
       "<td>16.0</td>\n",
       "<td>19.0</td>\n",
       "<td>14.0</td>\n",
       "<td>14.0</td>\n",
       "<td>26.0</td>\n",
       "<td>17.0</td>\n",
       "<td>19.0</td>\n",
       "<td>21.0</td>\n",
       "<td>18.0</td>\n",
       "<td>22.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.6499907</td>\n",
       "<td>0.0520304</td>\n",
       "<td>0.6711410</td>\n",
       "<td>0.5109489</td>\n",
       "<td>0.7051282</td>\n",
       "<td>0.7530121</td>\n",
       "<td>0.6275303</td>\n",
       "<td>0.7177033</td>\n",
       "<td>0.6329114</td>\n",
       "<td>0.6034483</td>\n",
       "<td>0.7194245</td>\n",
       "<td>0.5586592</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.6865607</td>\n",
       "<td>0.0416998</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.5957447</td>\n",
       "<td>0.6111111</td>\n",
       "<td>0.78125</td>\n",
       "<td>0.7045454</td>\n",
       "<td>0.7792208</td>\n",
       "<td>0.6779661</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.6896552</td>\n",
       "<td>0.6451613</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.7384148</td>\n",
       "<td>0.0591342</td>\n",
       "<td>0.7633588</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.5392157</td>\n",
       "<td>0.8116883</td>\n",
       "<td>0.8031088</td>\n",
       "<td>0.8522728</td>\n",
       "<td>0.729927</td>\n",
       "<td>0.7446808</td>\n",
       "<td>0.6622516</td>\n",
       "<td>0.7633588</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.6244342</td>\n",
       "<td>0.7108094</td>\n",
       "<td>2.68</td>\n",
       "<td>4.0</td>\n",
       "<td>3.5454545</td>\n",
       "<td>2.8333333</td>\n",
       "<td>2.3142858</td>\n",
       "<td>2.3030303</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.0</td>\n",
       "<td>2.6451614</td>\n",
       "<td>3.0</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.5769904</td>\n",
       "<td>0.0654631</td>\n",
       "<td>0.5396032</td>\n",
       "<td>0.5437901</td>\n",
       "<td>0.5971769</td>\n",
       "<td>0.4484487</td>\n",
       "<td>0.6946099</td>\n",
       "<td>0.4611931</td>\n",
       "<td>0.773882</td>\n",
       "<td>0.5706165</td>\n",
       "<td>0.5785912</td>\n",
       "<td>0.5619921</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.3340688</td>\n",
       "<td>0.0702635</td>\n",
       "<td>0.2619048</td>\n",
       "<td>0.3137255</td>\n",
       "<td>0.5</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.4782609</td>\n",
       "<td>0.3255814</td>\n",
       "<td>0.26</td>\n",
       "<td>0.2666667</td>\n",
       "<td>0.3548387</td>\n",
       "<td>0.4130435</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.5100931</td>\n",
       "<td>0.0472933</td>\n",
       "<td>0.5219414</td>\n",
       "<td>0.4445906</td>\n",
       "<td>0.5234839</td>\n",
       "<td>0.6532746</td>\n",
       "<td>0.4243986</td>\n",
       "<td>0.5857844</td>\n",
       "<td>0.4874108</td>\n",
       "<td>0.5018585</td>\n",
       "<td>0.5240665</td>\n",
       "<td>0.4341216</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.7584836</td>\n",
       "<td>0.0248986</td>\n",
       "<td>0.7690476</td>\n",
       "<td>0.7549020</td>\n",
       "<td>0.7232143</td>\n",
       "<td>0.8348485</td>\n",
       "<td>0.7037267</td>\n",
       "<td>0.7917548</td>\n",
       "<td>0.7546154</td>\n",
       "<td>0.7705128</td>\n",
       "<td>0.7539532</td>\n",
       "<td>0.7282609</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.2415164</td>\n",
       "<td>0.0248986</td>\n",
       "<td>0.2309524</td>\n",
       "<td>0.2450980</td>\n",
       "<td>0.2767857</td>\n",
       "<td>0.1651515</td>\n",
       "<td>0.2962733</td>\n",
       "<td>0.2082452</td>\n",
       "<td>0.2453846</td>\n",
       "<td>0.2294872</td>\n",
       "<td>0.2460468</td>\n",
       "<td>0.2717391</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1915044</td>\n",
       "<td>0.0215328</td>\n",
       "<td>0.1795407</td>\n",
       "<td>0.1853381</td>\n",
       "<td>0.2111395</td>\n",
       "<td>0.1503332</td>\n",
       "<td>0.2226509</td>\n",
       "<td>0.1526131</td>\n",
       "<td>0.2566420</td>\n",
       "<td>0.1855101</td>\n",
       "<td>0.1761206</td>\n",
       "<td>0.1951560</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.632675</td>\n",
       "<td>0.0697689</td>\n",
       "<td>0.6451613</td>\n",
       "<td>0.4666667</td>\n",
       "<td>0.7857143</td>\n",
       "<td>0.7352941</td>\n",
       "<td>0.5849057</td>\n",
       "<td>0.6818182</td>\n",
       "<td>0.6060606</td>\n",
       "<td>0.5675676</td>\n",
       "<td>0.7407407</td>\n",
       "<td>0.5128205</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.1367425</td>\n",
       "<td>0.1117686</td>\n",
       "<td>0.2324207</td>\n",
       "<td>0.0115301</td>\n",
       "<td>-0.0426725</td>\n",
       "<td>0.3417228</td>\n",
       "<td>0.0926631</td>\n",
       "<td>0.3787926</td>\n",
       "<td>-0.1402799</td>\n",
       "<td>0.1204916</td>\n",
       "<td>0.2509581</td>\n",
       "<td>0.1217981</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.7843317</td>\n",
       "<td>0.0831498</td>\n",
       "<td>0.8</td>\n",
       "<td>0.8235294</td>\n",
       "<td>0.5</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.8857143</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.7692308</td>\n",
       "<td>0.8076923</td>\n",
       "<td>0.6451613</td>\n",
       "<td>0.8695652</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.4362714</td>\n",
       "<td>0.0242038</td>\n",
       "<td>0.4237224</td>\n",
       "<td>0.4305091</td>\n",
       "<td>0.4594992</td>\n",
       "<td>0.3877283</td>\n",
       "<td>0.4718589</td>\n",
       "<td>0.3906573</td>\n",
       "<td>0.5065984</td>\n",
       "<td>0.4307089</td>\n",
       "<td>0.4196673</td>\n",
       "<td>0.4417646</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.7326354</td>\n",
       "<td>0.0850642</td>\n",
       "<td>0.7380952</td>\n",
       "<td>0.6862745</td>\n",
       "<td>0.9464286</td>\n",
       "<td>0.8363636</td>\n",
       "<td>0.5217391</td>\n",
       "<td>0.6744186</td>\n",
       "<td>0.74</td>\n",
       "<td>0.7333333</td>\n",
       "<td>0.8627451</td>\n",
       "<td>0.5869565</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean      sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid    cv_6_valid    cv_7_valid    cv_8_valid    cv_9_valid    cv_10_valid\n",
       "-----------------------  --------  ---------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  -------------\n",
       "accuracy                 0.756038  0.0348619  0.761194      0.720588      0.820513      0.835294      0.679012      0.776316      0.75          0.755814      0.780488      0.681159\n",
       "auc                      0.803707  0.0259543  0.800952      0.78316       0.760552      0.884849      0.770807      0.859056      0.791539      0.8           0.787476      0.798677\n",
       "err                      0.243962  0.0348619  0.238806      0.279412      0.179487      0.164706      0.320988      0.223684      0.25          0.244186      0.219512      0.318841\n",
       "err_count                18.6      2.49399    16            19            14            14            26            17            19            21            18            22\n",
       "f0point5                 0.649991  0.0520304  0.671141      0.510949      0.705128      0.753012      0.62753       0.717703      0.632911      0.603448      0.719425      0.558659\n",
       "f1                       0.686561  0.0416998  0.714286      0.595745      0.611111      0.78125       0.704545      0.779221      0.677966      0.666667      0.689655      0.645161\n",
       "f2                       0.738415  0.0591342  0.763359      0.714286      0.539216      0.811688      0.803109      0.852273      0.729927      0.744681      0.662252      0.763359\n",
       "lift_top_group           2.62443   0.710809   2.68          4             3.54545       2.83333       2.31429       2.30303       2.92308       0             2.64516       3\n",
       "logloss                  0.57699   0.0654631  0.539603      0.54379       0.597177      0.448449      0.69461       0.461193      0.773882      0.570616      0.578591      0.561992\n",
       "max_per_class_error      0.334069  0.0702635  0.261905      0.313725      0.5           0.166667      0.478261      0.325581      0.26          0.266667      0.354839      0.413043\n",
       "mcc                      0.510093  0.0472933  0.521941      0.444591      0.523484      0.653275      0.424399      0.585784      0.487411      0.501858      0.524066      0.434122\n",
       "mean_per_class_accuracy  0.758484  0.0248986  0.769048      0.754902      0.723214      0.834848      0.703727      0.791755      0.754615      0.770513      0.753953      0.728261\n",
       "mean_per_class_error     0.241516  0.0248986  0.230952      0.245098      0.276786      0.165152      0.296273      0.208245      0.245385      0.229487      0.246047      0.271739\n",
       "mse                      0.191504  0.0215328  0.179541      0.185338      0.211139      0.150333      0.222651      0.152613      0.256642      0.18551       0.176121      0.195156\n",
       "precision                0.632675  0.0697689  0.645161      0.466667      0.785714      0.735294      0.584906      0.681818      0.606061      0.567568      0.740741      0.512821\n",
       "r2                       0.136742  0.111769   0.232421      0.0115301     -0.0426725    0.341723      0.0926631     0.378793      -0.14028      0.120492      0.250958      0.121798\n",
       "recall                   0.784332  0.0831498  0.8           0.823529      0.5           0.833333      0.885714      0.909091      0.769231      0.807692      0.645161      0.869565\n",
       "rmse                     0.436271  0.0242038  0.423722      0.430509      0.459499      0.387728      0.471859      0.390657      0.506598      0.430709      0.419667      0.441765\n",
       "specificity              0.732635  0.0850642  0.738095      0.686275      0.946429      0.836364      0.521739      0.674419      0.74          0.733333      0.862745      0.586956"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_r2</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-10 15:57:23</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-10 15:57:23</td>\n",
       "<td>22.535 sec</td>\n",
       "<td>101052 obs/sec</td>\n",
       "<td>10.0</td>\n",
       "<td>1</td>\n",
       "<td>7680.0</td>\n",
       "<td>0.4120174</td>\n",
       "<td>0.5063453</td>\n",
       "<td>0.2527797</td>\n",
       "<td>0.8350075</td>\n",
       "<td>0.7280777</td>\n",
       "<td>2.5074627</td>\n",
       "<td>0.2630208</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-10 15:57:26</td>\n",
       "<td>25.293 sec</td>\n",
       "<td>143105 obs/sec</td>\n",
       "<td>510.0</td>\n",
       "<td>51</td>\n",
       "<td>391680.0</td>\n",
       "<td>0.1895796</td>\n",
       "<td>0.1289077</td>\n",
       "<td>0.8418020</td>\n",
       "<td>0.9903582</td>\n",
       "<td>0.7598401</td>\n",
       "<td>2.8656716</td>\n",
       "<td>0.0416667</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_logloss    training_r2    training_auc    training_pr_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  ------------------  -------------  --------------  -----------------  ---------------  -------------------------------\n",
       "    2019-04-10 15:57:23  0.000 sec                     0         0             0          nan              nan                 nan            nan             nan                nan              nan\n",
       "    2019-04-10 15:57:23  22.535 sec  101052 obs/sec    10        1             7680       0.412017         0.506345            0.25278        0.835007        0.728078           2.50746          0.263021\n",
       "    2019-04-10 15:57:26  25.293 sec  143105 obs/sec    510       51            391680     0.18958          0.128908            0.841802       0.990358        0.75984            2.86567          0.0416667"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>C6</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1492088</td></tr>\n",
       "<tr><td>C8</td>\n",
       "<td>0.9795488</td>\n",
       "<td>0.9795488</td>\n",
       "<td>0.1461573</td></tr>\n",
       "<tr><td>C5</td>\n",
       "<td>0.8759125</td>\n",
       "<td>0.8759125</td>\n",
       "<td>0.1306938</td></tr>\n",
       "<tr><td>C2</td>\n",
       "<td>0.8488727</td>\n",
       "<td>0.8488727</td>\n",
       "<td>0.1266592</td></tr>\n",
       "<tr><td>C1</td>\n",
       "<td>0.8143702</td>\n",
       "<td>0.8143702</td>\n",
       "<td>0.1215112</td></tr>\n",
       "<tr><td>C7</td>\n",
       "<td>0.7718349</td>\n",
       "<td>0.7718349</td>\n",
       "<td>0.1151645</td></tr>\n",
       "<tr><td>C3</td>\n",
       "<td>0.7069308</td>\n",
       "<td>0.7069308</td>\n",
       "<td>0.1054803</td></tr>\n",
       "<tr><td>C4</td>\n",
       "<td>0.7045498</td>\n",
       "<td>0.7045498</td>\n",
       "<td>0.1051250</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "C6          1                      1                    0.149209\n",
       "C8          0.979549               0.979549             0.146157\n",
       "C5          0.875912               0.875912             0.130694\n",
       "C2          0.848873               0.848873             0.126659\n",
       "C1          0.81437                0.81437              0.121511\n",
       "C7          0.771835               0.771835             0.115165\n",
       "C3          0.706931               0.706931             0.10548\n",
       "C4          0.70455                0.70455              0.105125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OBinomialModel.confusion_matrix of >"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_model1.confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### V . Ejemplo de deep Learning aplicado a Shuttle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "deeplearning Model Build progress: |██████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "shuttle = h2o.import_file(\"https://academic.uprm.edu/eacuna/shuttle.trn\")\n",
    "myx=['C1','C2','C3','C4','C5','C6','C7','C8','C9']\n",
    "shuttle['C10']=shuttle['C10'].asfactor()\n",
    "myy=\"C10\"\n",
    "dl_model = H2ODeepLearningEstimator(hidden=[10,20],epochs=200)\n",
    "dl_model.train(myx, myy, training_frame=shuttle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deeplearning prediction progress: |███████████████████████████████████████| 100%\n",
      "[0.9991724137931034]\n"
     ]
    }
   ],
   "source": [
    "y_pred=dl_model.predict(shuttle)\n",
    "print ((y_pred['predict']==shuttle['C10']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.0007287421780119474\n",
      "RMSE: 0.02699522509652304\n",
      "LogLoss: 0.01133192223189198\n",
      "Mean Per-Class Error: 0.1479383777212571\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>34103.0</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0001466</td>\n",
       "<td>5 / 34,108</td></tr>\n",
       "<tr><td>2.0</td>\n",
       "<td>33.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1081081</td>\n",
       "<td>4 / 37</td></tr>\n",
       "<tr><td>7.0</td>\n",
       "<td>0.0</td>\n",
       "<td>124.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0606061</td>\n",
       "<td>8 / 132</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>6741.0</td>\n",
       "<td>3.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0010373</td>\n",
       "<td>7 / 6,748</td></tr>\n",
       "<tr><td>2.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>2453.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0020342</td>\n",
       "<td>5 / 2,458</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>2.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5</td>\n",
       "<td>3 / 6</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>3.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>7.0</td>\n",
       "<td>0.3636364</td>\n",
       "<td>4 / 11</td></tr>\n",
       "<tr><td>34116.0</td>\n",
       "<td>38.0</td>\n",
       "<td>128.0</td>\n",
       "<td>6746.0</td>\n",
       "<td>2458.0</td>\n",
       "<td>4.0</td>\n",
       "<td>10.0</td>\n",
       "<td>0.0008276</td>\n",
       "<td>36 / 43,500</td></tr></table></div>"
      ],
      "text/plain": [
       "1      2    3    4     5     6    7    Error        Rate\n",
       "-----  ---  ---  ----  ----  ---  ---  -----------  -----------\n",
       "34103  1    1    0     0     0    3    0.000146593  5 / 34,108\n",
       "2      33   0    2     0     0    0    0.108108     4 / 37\n",
       "7      0    124  1     0     0    0    0.0606061    8 / 132\n",
       "1      2    0    6741  3     1    0    0.00103734   7 / 6,748\n",
       "2      1    0    2     2453  0    0    0.00203417   5 / 2,458\n",
       "0      1    0    0     2     3    0    0.5          3 / 6\n",
       "1      0    3    0     0     0    7    0.363636     4 / 11\n",
       "34116  38   128  6746  2458  4    10   0.000827586  36 / 43,500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9991724</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.9997930</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.999862</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.999908</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9999539</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9999999</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9999999</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.999172\n",
       "2    0.999793\n",
       "3    0.999862\n",
       "4    0.999908\n",
       "5    0.999954\n",
       "6    1\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_model.model_performance(shuttle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2ODeepLearningEstimator :  Deep Learning\n",
      "Model Key:  DeepLearning_model_python_1554922755540_182\n",
      "\n",
      "\n",
      "ModelMetricsMultinomial: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0006403760638900163\n",
      "RMSE: 0.02530565280505556\n",
      "LogLoss: 0.003983718782887604\n",
      "Mean Per-Class Error: 0.05944570040578628\n",
      "Confusion Matrix: Row labels: Actual class; Column labels: Predicted class\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>7688.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0002601</td>\n",
       "<td>2 / 7,690</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>4.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3333333</td>\n",
       "<td>2 / 6</td></tr>\n",
       "<tr><td>2.0</td>\n",
       "<td>0.0</td>\n",
       "<td>23.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.08</td>\n",
       "<td>2 / 25</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1571.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0006361</td>\n",
       "<td>1 / 1,572</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>528.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0018904</td>\n",
       "<td>1 / 529</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 1</td></tr>\n",
       "<tr><td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0 / 1</td></tr>\n",
       "<tr><td>7691.0</td>\n",
       "<td>6.0</td>\n",
       "<td>23.0</td>\n",
       "<td>1573.0</td>\n",
       "<td>528.0</td>\n",
       "<td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>0.0008143</td>\n",
       "<td>8 / 9,824</td></tr></table></div>"
      ],
      "text/plain": [
       "1     2    3    4     5    6    7    Error        Rate\n",
       "----  ---  ---  ----  ---  ---  ---  -----------  ---------\n",
       "7688  1    0    0     0    0    1    0.000260078  2 / 7,690\n",
       "1     4    0    1     0    0    0    0.333333     2 / 6\n",
       "2     0    23   0     0    0    0    0.08         2 / 25\n",
       "0     1    0    1571  0    0    0    0.000636132  1 / 1,572\n",
       "0     0    0    1     528  0    0    0.00189036   1 / 529\n",
       "0     0    0    0     0    1    0    0            0 / 1\n",
       "0     0    0    0     0    0    1    0            0 / 1\n",
       "7691  6    23   1573  528  1    2    0.000814332  8 / 9,824"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-7 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.9991857</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>1.0</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.999186\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "5    1\n",
       "6    1\n",
       "7    1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>training_speed</b></td>\n",
       "<td><b>epochs</b></td>\n",
       "<td><b>iterations</b></td>\n",
       "<td><b>samples</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_r2</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-10 15:57:46</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>None</td>\n",
       "<td>0.0</td>\n",
       "<td>0</td>\n",
       "<td>0.0</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td>\n",
       "<td>nan</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-10 15:57:46</td>\n",
       "<td> 0.708 sec</td>\n",
       "<td>204707 obs/sec</td>\n",
       "<td>2.3011954</td>\n",
       "<td>1</td>\n",
       "<td>100102.0</td>\n",
       "<td>0.0641727</td>\n",
       "<td>0.0338891</td>\n",
       "<td>0.9977442</td>\n",
       "<td>0.0033591</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-10 15:57:51</td>\n",
       "<td> 5.854 sec</td>\n",
       "<td>249561 obs/sec</td>\n",
       "<td>32.2020230</td>\n",
       "<td>14</td>\n",
       "<td>1400788.0</td>\n",
       "<td>0.0493383</td>\n",
       "<td>0.0269791</td>\n",
       "<td>0.9986666</td>\n",
       "<td>0.0026466</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-10 15:57:57</td>\n",
       "<td>11.267 sec</td>\n",
       "<td>254389 obs/sec</td>\n",
       "<td>64.3752644</td>\n",
       "<td>28</td>\n",
       "<td>2800324.0</td>\n",
       "<td>0.0429850</td>\n",
       "<td>0.0257754</td>\n",
       "<td>0.9989879</td>\n",
       "<td>0.0019340</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-10 15:58:02</td>\n",
       "<td>16.465 sec</td>\n",
       "<td>253274 obs/sec</td>\n",
       "<td>94.2472184</td>\n",
       "<td>41</td>\n",
       "<td>4099754.0</td>\n",
       "<td>0.0314264</td>\n",
       "<td>0.0181081</td>\n",
       "<td>0.9994590</td>\n",
       "<td>0.0010179</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-10 15:58:07</td>\n",
       "<td>21.479 sec</td>\n",
       "<td>250268 obs/sec</td>\n",
       "<td>121.8431264</td>\n",
       "<td>53</td>\n",
       "<td>5300176.0</td>\n",
       "<td>0.0306157</td>\n",
       "<td>0.0130338</td>\n",
       "<td>0.9994866</td>\n",
       "<td>0.0011197</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-10 15:58:12</td>\n",
       "<td>26.521 sec</td>\n",
       "<td>248130 obs/sec</td>\n",
       "<td>149.4372414</td>\n",
       "<td>65</td>\n",
       "<td>6500520.0</td>\n",
       "<td>0.0248363</td>\n",
       "<td>0.0059661</td>\n",
       "<td>0.9996621</td>\n",
       "<td>0.0006107</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-10 15:58:17</td>\n",
       "<td>31.632 sec</td>\n",
       "<td>246133 obs/sec</td>\n",
       "<td>177.0348046</td>\n",
       "<td>77</td>\n",
       "<td>7701014.0</td>\n",
       "<td>0.0265568</td>\n",
       "<td>0.0058078</td>\n",
       "<td>0.9996137</td>\n",
       "<td>0.0008143</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-04-10 15:58:21</td>\n",
       "<td>35.639 sec</td>\n",
       "<td>246649 obs/sec</td>\n",
       "<td>200.0359310</td>\n",
       "<td>87</td>\n",
       "<td>8701563.0</td>\n",
       "<td>0.0253057</td>\n",
       "<td>0.0039837</td>\n",
       "<td>0.9996492</td>\n",
       "<td>0.0008143</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    training_speed    epochs    iterations    samples      training_rmse    training_logloss    training_r2    training_classification_error\n",
       "--  -------------------  ----------  ----------------  --------  ------------  -----------  ---------------  ------------------  -------------  -------------------------------\n",
       "    2019-04-10 15:57:46  0.000 sec                     0         0             0            nan              nan                 nan            nan\n",
       "    2019-04-10 15:57:46  0.708 sec   204707 obs/sec    2.3012    1             100102       0.0641727        0.0338891           0.997744       0.00335912\n",
       "    2019-04-10 15:57:51  5.854 sec   249561 obs/sec    32.202    14            1.40079e+06  0.0493383        0.0269791           0.998667       0.00264658\n",
       "    2019-04-10 15:57:57  11.267 sec  254389 obs/sec    64.3753   28            2.80032e+06  0.042985         0.0257754           0.998988       0.00193404\n",
       "    2019-04-10 15:58:02  16.465 sec  253274 obs/sec    94.2472   41            4.09975e+06  0.0314264        0.0181081           0.999459       0.00101792\n",
       "    2019-04-10 15:58:07  21.479 sec  250268 obs/sec    121.843   53            5.30018e+06  0.0306157        0.0130338           0.999487       0.00111971\n",
       "    2019-04-10 15:58:12  26.521 sec  248130 obs/sec    149.437   65            6.50052e+06  0.0248363        0.0059661           0.999662       0.000610749\n",
       "    2019-04-10 15:58:17  31.632 sec  246133 obs/sec    177.035   77            7.70101e+06  0.0265568        0.00580777          0.999614       0.000814332\n",
       "    2019-04-10 15:58:21  35.639 sec  246649 obs/sec    200.036   87            8.70156e+06  0.0253057        0.00398372          0.999649       0.000814332"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>C2</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1724543</td></tr>\n",
       "<tr><td>C5</td>\n",
       "<td>0.9822453</td>\n",
       "<td>0.9822453</td>\n",
       "<td>0.1693925</td></tr>\n",
       "<tr><td>C9</td>\n",
       "<td>0.9173821</td>\n",
       "<td>0.9173821</td>\n",
       "<td>0.1582065</td></tr>\n",
       "<tr><td>C8</td>\n",
       "<td>0.8356099</td>\n",
       "<td>0.8356099</td>\n",
       "<td>0.1441045</td></tr>\n",
       "<tr><td>C1</td>\n",
       "<td>0.6111780</td>\n",
       "<td>0.6111780</td>\n",
       "<td>0.1054003</td></tr>\n",
       "<tr><td>C7</td>\n",
       "<td>0.5444348</td>\n",
       "<td>0.5444348</td>\n",
       "<td>0.0938901</td></tr>\n",
       "<tr><td>C3</td>\n",
       "<td>0.3922257</td>\n",
       "<td>0.3922257</td>\n",
       "<td>0.0676410</td></tr>\n",
       "<tr><td>C6</td>\n",
       "<td>0.3219854</td>\n",
       "<td>0.3219854</td>\n",
       "<td>0.0555278</td></tr>\n",
       "<tr><td>C4</td>\n",
       "<td>0.1935758</td>\n",
       "<td>0.1935758</td>\n",
       "<td>0.0333830</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "C2          1                      1                    0.172454\n",
       "C5          0.982245               0.982245             0.169392\n",
       "C9          0.917382               0.917382             0.158207\n",
       "C8          0.83561                0.83561              0.144105\n",
       "C1          0.611178               0.611178             0.1054\n",
       "C7          0.544435               0.544435             0.0938901\n",
       "C3          0.392226               0.392226             0.067641\n",
       "C6          0.321985               0.321985             0.0555278\n",
       "C4          0.193576               0.193576             0.033383"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<bound method H2OMultinomialModel.confusion_matrix of >"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_model.confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
